{
    "docs": [
        {
            "location": "/", 
            "text": "Ultimate Ansible Bootcamp\n\n\n\n\n Chapter 1: Introduction to Ansible (TBA) \n\n\n Chapter 2: Setting up Learning Environment (TBA) \n\n\nChapter 3: Ad Hoc Server Management  Management\n\n\n Chapter 4: Modules - The Batteries Included \n\n\n Chapter 5: Playbooks - Learning to Write Infrastructure as a Code \n\n\nChapter 6: Working with Roles \n\n\nChapter 7: Variables and Templates\n\n\nChapter 8: Control Structures\n\n\n\n\nLicense (CC-BY-NC-ND)\n\n\nUltimate Ansible Bootcamp\n by \nSchool of Devops\n is licensed under a \nCreative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#ultimate-ansible-bootcamp", 
            "text": "Chapter 1: Introduction to Ansible (TBA)    Chapter 2: Setting up Learning Environment (TBA)   Chapter 3: Ad Hoc Server Management  Management   Chapter 4: Modules - The Batteries Included    Chapter 5: Playbooks - Learning to Write Infrastructure as a Code   Chapter 6: Working with Roles   Chapter 7: Variables and Templates  Chapter 8: Control Structures", 
            "title": "Ultimate Ansible Bootcamp"
        }, 
        {
            "location": "/#license-cc-by-nc-nd", 
            "text": "Ultimate Ansible Bootcamp  by  School of Devops  is licensed under a  Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .", 
            "title": "License (CC-BY-NC-ND)"
        }, 
        {
            "location": "/ad-hoc/", 
            "text": "Getting Started with Ansible (Ad Hoc Server Management)\n\n\nCreating Project Specific Ansible Configuration\n\n\nThe default configurations for ansible resides at /etc/ansible/ansible.cfg. Instead of relying on defaults, we are going to creates  a custom configuration file for our project. The advantage with that is we could take this configurations on any host and execute it the same way, without touching the default system configurations.  This custom configurations will essentially  override the values in /etc/ansible/ansible/cfg.\n\n\nAnsible configuration file\n\n\nChange into /vagrant/code/chap3 directory on your ansible host. Create a file called ansible.cfg  Add  the following contents to the file.\n\n\nOn Ansible Control node,\n\n\nmkdir /vagrant/code/chap3\ncd /vagrant/code/chap3\n\n\n\n\nCreate \nansible.cfg\n in chap3\n\n\n[defaults]\nremote_user = vagrant\ninventory   = myhosts.ini\n\n\n\n\nCreating Host Inventory\n\n\nCreate a new file called \nmyhosts.ini\n in the same directory.\nLet's create three groups as follows,\n\n\n[local]\nlocalhost ansible_connection=local\n\n[app]\n192.168.61.12\n192.168.61.13\n\n[db]\n192.168.61.11\n\n\n\n\n\n\nFirst group contains the localhost, the control host. Since it does not need to be connected over ssh, it mandates we add ansible_connection=local option\n\n\nSecond group contains  Application Servers. We will add  two app servers to this group.\n\n\nThird group holds the information about the database servers.\n\n\n\n\nThe inventory file should look like below.\n\n\nSetting up passwordless ssh access to inventory hosts\n\n\nGenerating ssh keypair on control host\n\n\nNow on control host, execute the following command\n\n\nssh-keygen -t rsa\n\n\n\n\nNow press enter for the passphrase and other queries.\n\n\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa):\nCreated directory '/root/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nc5:a5:6d:60:56:5a:7b:3c:60:23:b5:0f:1b:cf:f9:fd root@ansible\nThe key's randomart image is:\n+--[ RSA 2048]----+\n|          =oO    |\n|         + X *   |\n|          = B +  |\n|         . . O o |\n|        S   . =  |\n|               ..|\n|                o|\n|                .|\n|                E|\n+-----------------+\n\n\n\n\nCopying public key to inventory hosts\n\n\nCopy public key of control node to other hosts\n\n\nssh-copy-id vagrant@192.168.61.11\n\nssh-copy-id vagrant@192.168.61.12\n\nssh-copy-id vagrant@192.168.61.13\n\nssh-copy-id vagrant@192.168.61.14\n\n\n\n\nSee this example output to verify with your output\n\n\nThe authenticity of host '192.168.61.11 (192.168.61.11)' can't be established.\nRSA key fingerprint is 32:7f:ad:d7:da:63:32:b6:a9:ff:59:af:09:1e:56:22.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added '192.168.61.11' (RSA) to the list of known hosts.\n\n\n\n\nThe password for user \nvagrant\n is \nvagrant\n\n\nValidate the passwordless login\n\n\nLet us check the connection of control node with other hosts\n\n\nssh vagrant@192.168.61.11\n\nssh vagrant@192.168.61.12\n\nssh vagrant@192.168.61.13\n\nssh vagrant@192.168.61.14\n\n\n\n\nAnsible ping\n\n\nWe will use Ansible to make sure all the hosts are reachable\n\n\nansible all -m ping\n\n\n\n\n\n[Output]\n\n\n192.168.61.13 | SUCCESS =\n {\n    \nchanged\n: false,\n    \nping\n: \npong\n\n}\n192.168.61.11 | SUCCESS =\n {\n    \nchanged\n: false,\n    \nping\n: \npong\n\n}\n192.168.61.12 | SUCCESS =\n {\n    \nchanged\n: false,\n    \nping\n: \npong\n\n}\nlocalhost | SUCCESS =\n {\n    \nchanged\n: false,\n    \nping\n: \npong\n\n}\n\n\n\n\nAd Hoc commands\n\n\nTry running following \nfire-and-forget\n Ad-Hoc commands...\n\n\nRun \nhostname\n command on all hosts\n\n\nLet us print the hostname of all the hosts\n\n\nansible all -a hostname\n\n\n\n\n[output]\n\n\nlocalhost | SUCCESS | rc=0 \n\nansible\n\n192.168.61.11 | SUCCESS | rc=0 \n\ndb\n\n192.168.61.12 | SUCCESS | rc=0 \n\napp\n\n192.168.61.13 | SUCCESS | rc=0 \n\napp\n\n\n\n\nCheck the \nuptime\n\n\nHow long the hosts are \nup\n?\n\n\nansible all -a uptime\n\n\n\n\n[Output]\n\n\nlocalhost | SUCCESS | rc=0 \n\n 13:17:13 up  2:21,  1 user,  load average: 0.16, 0.03, 0.01\n\n192.168.61.12 | SUCCESS | rc=0 \n\n 13:17:14 up  1:50,  2 users,  load average: 0.00, 0.00, 0.00\n\n192.168.61.13 | SUCCESS | rc=0 \n\n 13:17:14 up  1:47,  2 users,  load average: 0.00, 0.00, 0.00\n\n192.168.61.11 | SUCCESS | rc=0 \n\n 13:17:14 up  1:36,  2 users,  load average: 0.00, 0.00, 0.00\n\n\n\n\nCheck memory info on app servers\n\n\nDoes my app servers have any disk space \nfree\n?\n\n\nansible app -a free\n\n\n\n\n[Output]\n\n\n192.168.61.13 | SUCCESS | rc=0 \n\n             total       used       free     shared    buffers     cached\nMem:        372916     121480     251436        776      11160      46304\n-/+ buffers/cache:      64016     308900\nSwap:      4128764          0    4128764\n\n192.168.61.12 | SUCCESS | rc=0 \n\n             total       used       free     shared    buffers     cached\nMem:        372916     121984     250932        776      11228      46336\n-/+ buffers/cache:      64420     308496\nSwap:      4128764          0    4128764\n\n\n\n\nInstalling packages\n\n\nLet us \ninstall\n Docker on app servers\n\n\nansible app -a \nyum install -y docker-engine\n\n\n\n\n\nThis command will fail.\n\n\n[Output]\n\n\n192.168.61.13 | FAILED | rc=1 \n\nLoaded plugins: fastestmirror, prioritiesYou need to be root to perform this command.\n\n192.168.61.12 | FAILED | rc=1 \n\nLoaded plugins: fastestmirror, prioritiesYou need to be root to perform this command.\n\n\n\n\nRun the fillowing command with sudo permissions.\n\n\nansible app -s -a \nyum install -y docker-engine\n\n\n\n\n\nThis will install docker in our app servers\n\n\n[Output]\n\n\n192.168.61.12 | SUCCESS | rc=0 \n\nLoaded plugins: fastestmirror, priorities\nSetting up Install Process\nLoading mirror speeds from cached hostfile\n * base: mirrors.nhanhoa.com\n * epel: mirror.rise.ph\n * extras: mirror.fibergrid.in\n * updates: mirror.fibergrid.in\n283 packages excluded due to repository priority protections\nResolving Dependencies\n--\n Running transaction check\n---\n Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed\n--\n Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package             Arch         Version              Repository          Size\n================================================================================\nInstalling:\n docker-engine       x86_64       1.7.1-1.el6          local_docker       4.5 M\n\nTransaction Summary\n================================================================================\nInstall       1 Package(s)\n\nTotal download size: 4.5 M\nInstalled size: 19 M\nDownloading Packages:\nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\n  Installing : docker-engine-1.7.1-1.el6.x86_64                             1/1\n  Verifying  : docker-engine-1.7.1-1.el6.x86_64                             1/1\n\nInstalled:\n  docker-engine.x86_64 0:1.7.1-1.el6\n\nComplete!\n\n192.168.61.13 | SUCCESS | rc=0 \n\nLoaded plugins: fastestmirror, priorities\nSetting up Install Process\nLoading mirror speeds from cached hostfile\n * base: mirror.fibergrid.in\n * epel: mirror.rise.ph\n * extras: mirror.fibergrid.in\n * updates: mirror.fibergrid.in\n283 packages excluded due to repository priority protections\nResolving Dependencies\n--\n Running transaction check\n---\n Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed\n--\n Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package             Arch         Version              Repository          Size\n================================================================================\nInstalling:\n docker-engine       x86_64       1.7.1-1.el6          local_docker       4.5 M\n\nTransaction Summary\n================================================================================\nInstall       1 Package(s)\n\nTotal download size: 4.5 M\nInstalled size: 19 M\nDownloading Packages:\nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\n  Installing : docker-engine-1.7.1-1.el6.x86_64                             1/1\n  Verifying  : docker-engine-1.7.1-1.el6.x86_64                             1/1\n\nInstalled:\n  docker-engine.x86_64 0:1.7.1-1.el6\n\nComplete!\n\n\n\n\nRunning commands one machine at a time\n\n\nDo you want a command to run on \none machine at a time\n ?\n\n\nansible all -f 1 -a \nfree\n\n\n\n\n\nUsing \nmodules\n to manage the state of infrastructure\n\n\nCreating users and groups using \nuser\n and \ngroup\n\n\nTo create a group\n\n\nansible app -s -m group -a \nname=admin state=present\n\n\n\n\n\nThe output will be,\n\n\n192.168.61.13 | SUCCESS =\n {\n    \nchanged\n: true,\n    \ngid\n: 501,\n    \nname\n: \nadmin\n,\n    \nstate\n: \npresent\n,\n    \nsystem\n: false\n}\n192.168.61.12 | SUCCESS =\n {\n    \nchanged\n: true,\n    \ngid\n: 501,\n    \nname\n: \nadmin\n,\n    \nstate\n: \npresent\n,\n    \nsystem\n: false\n}\n\n\n\n\nTo create a user\n\n\nansible app -s -m user -a \nname=devops group=admin createhome=yes\n\n\n\n\n\nThis will create user \ndevops\n,\n\n\n192.168.61.13 | SUCCESS =\n {\n    \nchanged\n: true,\n    \ncomment\n: \n,\n    \ncreatehome\n: true,\n    \ngroup\n: 501,\n    \nhome\n: \n/home/devops\n,\n    \nname\n: \ndevops\n,\n    \nshell\n: \n/bin/bash\n,\n    \nstate\n: \npresent\n,\n    \nsystem\n: false,\n    \nuid\n: 501\n}\n192.168.61.12 | SUCCESS =\n {\n    \nchanged\n: true,\n    \ncomment\n: \n,\n    \ncreatehome\n: true,\n    \ngroup\n: 501,\n    \nhome\n: \n/home/devops\n,\n    \nname\n: \ndevops\n,\n    \nshell\n: \n/bin/bash\n,\n    \nstate\n: \npresent\n,\n    \nsystem\n: false,\n    \nuid\n: 501\n}\n\n\n\n\nCopy a file using \ncopy\n modules\n\n\nWe will copy file from control node to app servers.\n\n\nansible app -m copy -a \nsrc=/vagrant/test.txt dest=/tmp/test.txt\n\n\n\n\n\nFile will be copied over to our app server machines...\n\n\n192.168.61.13 | SUCCESS =\n {\n    \nchanged\n: true,\n    \nchecksum\n: \n3160f8f941c330444aac253a9e6420cd1a65bfe2\n,\n    \ndest\n: \n/tmp/test.txt\n,\n    \ngid\n: 500,\n    \ngroup\n: \nvagrant\n,\n    \nmd5sum\n: \n9052de4cff7e8a18de586f785e711b97\n,\n    \nmode\n: \n0664\n,\n    \nowner\n: \nvagrant\n,\n    \nsize\n: 11,\n    \nsrc\n: \n/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.29-63683023616899/source\n,\n    \nstate\n: \nfile\n,\n    \nuid\n: 500\n}\n192.168.61.12 | SUCCESS =\n {\n    \nchanged\n: true,\n    \nchecksum\n: \n3160f8f941c330444aac253a9e6420cd1a65bfe2\n,\n    \ndest\n: \n/tmp/test.txt\n,\n    \ngid\n: 500,\n    \ngroup\n: \nvagrant\n,\n    \nmd5sum\n: \n9052de4cff7e8a18de586f785e711b97\n,\n    \nmode\n: \n0664\n,\n    \nowner\n: \nvagrant\n,\n    \nsize\n: 11,\n    \nsrc\n: \n/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.26-218089785548663/source\n,\n    \nstate\n: \nfile\n,\n    \nuid\n: 500\n}\n\n\n\n\n\nExercises:\n\n\n\n\nAdd another system group (not inventory group) called \nlb\n in inventory with respective host ip\n\n\nAdd a system user called \njoe\n on all  app servers. Make sure that the user has a home directory\n\n\nInstall  package \nvim\n using the correct \nAd-Hoc\n command\n\n\nExamine all the available module\nhttp://docs.ansible.com/ansible/modules_by_category.html\n\n\nFind out the difference between the \ncommand\n module and \nshell\n module. Try running the following command with both these modules,\n\n\n\n\nfree | grep -i swap\n\n\n\n\n\n\n\nUse command module to show \nuptime\n on the host  \n\n\nInstall docker-engine using the yum/apt module\n\n\nUsing docker-image module, pull \nhello-world\n image on web server", 
            "title": "Ad Hoc Server Management"
        }, 
        {
            "location": "/ad-hoc/#getting-started-with-ansible-ad-hoc-server-management", 
            "text": "", 
            "title": "Getting Started with Ansible (Ad Hoc Server Management)"
        }, 
        {
            "location": "/ad-hoc/#creating-project-specific-ansible-configuration", 
            "text": "The default configurations for ansible resides at /etc/ansible/ansible.cfg. Instead of relying on defaults, we are going to creates  a custom configuration file for our project. The advantage with that is we could take this configurations on any host and execute it the same way, without touching the default system configurations.  This custom configurations will essentially  override the values in /etc/ansible/ansible/cfg.", 
            "title": "Creating Project Specific Ansible Configuration"
        }, 
        {
            "location": "/ad-hoc/#ansible-configuration-file", 
            "text": "Change into /vagrant/code/chap3 directory on your ansible host. Create a file called ansible.cfg  Add  the following contents to the file.  On Ansible Control node,  mkdir /vagrant/code/chap3\ncd /vagrant/code/chap3  Create  ansible.cfg  in chap3  [defaults]\nremote_user = vagrant\ninventory   = myhosts.ini", 
            "title": "Ansible configuration file"
        }, 
        {
            "location": "/ad-hoc/#creating-host-inventory", 
            "text": "Create a new file called  myhosts.ini  in the same directory.\nLet's create three groups as follows,  [local]\nlocalhost ansible_connection=local\n\n[app]\n192.168.61.12\n192.168.61.13\n\n[db]\n192.168.61.11   First group contains the localhost, the control host. Since it does not need to be connected over ssh, it mandates we add ansible_connection=local option  Second group contains  Application Servers. We will add  two app servers to this group.  Third group holds the information about the database servers.   The inventory file should look like below.", 
            "title": "Creating Host Inventory"
        }, 
        {
            "location": "/ad-hoc/#setting-up-passwordless-ssh-access-to-inventory-hosts", 
            "text": "", 
            "title": "Setting up passwordless ssh access to inventory hosts"
        }, 
        {
            "location": "/ad-hoc/#generating-ssh-keypair-on-control-host", 
            "text": "Now on control host, execute the following command  ssh-keygen -t rsa  Now press enter for the passphrase and other queries.  Generating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa):\nCreated directory '/root/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nc5:a5:6d:60:56:5a:7b:3c:60:23:b5:0f:1b:cf:f9:fd root@ansible\nThe key's randomart image is:\n+--[ RSA 2048]----+\n|          =oO    |\n|         + X *   |\n|          = B +  |\n|         . . O o |\n|        S   . =  |\n|               ..|\n|                o|\n|                .|\n|                E|\n+-----------------+", 
            "title": "Generating ssh keypair on control host"
        }, 
        {
            "location": "/ad-hoc/#copying-public-key-to-inventory-hosts", 
            "text": "Copy public key of control node to other hosts  ssh-copy-id vagrant@192.168.61.11\n\nssh-copy-id vagrant@192.168.61.12\n\nssh-copy-id vagrant@192.168.61.13\n\nssh-copy-id vagrant@192.168.61.14  See this example output to verify with your output  The authenticity of host '192.168.61.11 (192.168.61.11)' can't be established.\nRSA key fingerprint is 32:7f:ad:d7:da:63:32:b6:a9:ff:59:af:09:1e:56:22.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added '192.168.61.11' (RSA) to the list of known hosts.  The password for user  vagrant  is  vagrant", 
            "title": "Copying public key to inventory hosts"
        }, 
        {
            "location": "/ad-hoc/#validate-the-passwordless-login", 
            "text": "Let us check the connection of control node with other hosts  ssh vagrant@192.168.61.11\n\nssh vagrant@192.168.61.12\n\nssh vagrant@192.168.61.13\n\nssh vagrant@192.168.61.14", 
            "title": "Validate the passwordless login"
        }, 
        {
            "location": "/ad-hoc/#ansible-ping", 
            "text": "We will use Ansible to make sure all the hosts are reachable  ansible all -m ping  [Output]  192.168.61.13 | SUCCESS =  {\n     changed : false,\n     ping :  pong \n}\n192.168.61.11 | SUCCESS =  {\n     changed : false,\n     ping :  pong \n}\n192.168.61.12 | SUCCESS =  {\n     changed : false,\n     ping :  pong \n}\nlocalhost | SUCCESS =  {\n     changed : false,\n     ping :  pong \n}", 
            "title": "Ansible ping"
        }, 
        {
            "location": "/ad-hoc/#ad-hoc-commands", 
            "text": "Try running following  fire-and-forget  Ad-Hoc commands...", 
            "title": "Ad Hoc commands"
        }, 
        {
            "location": "/ad-hoc/#run-hostname-command-on-all-hosts", 
            "text": "Let us print the hostname of all the hosts  ansible all -a hostname  [output]  localhost | SUCCESS | rc=0  \nansible\n\n192.168.61.11 | SUCCESS | rc=0  \ndb\n\n192.168.61.12 | SUCCESS | rc=0  \napp\n\n192.168.61.13 | SUCCESS | rc=0  \napp", 
            "title": "Run hostname command on all hosts"
        }, 
        {
            "location": "/ad-hoc/#check-the-uptime", 
            "text": "How long the hosts are  up ?  ansible all -a uptime  [Output]  localhost | SUCCESS | rc=0  \n 13:17:13 up  2:21,  1 user,  load average: 0.16, 0.03, 0.01\n\n192.168.61.12 | SUCCESS | rc=0  \n 13:17:14 up  1:50,  2 users,  load average: 0.00, 0.00, 0.00\n\n192.168.61.13 | SUCCESS | rc=0  \n 13:17:14 up  1:47,  2 users,  load average: 0.00, 0.00, 0.00\n\n192.168.61.11 | SUCCESS | rc=0  \n 13:17:14 up  1:36,  2 users,  load average: 0.00, 0.00, 0.00", 
            "title": "Check the uptime"
        }, 
        {
            "location": "/ad-hoc/#check-memory-info-on-app-servers", 
            "text": "Does my app servers have any disk space  free ?  ansible app -a free  [Output]  192.168.61.13 | SUCCESS | rc=0  \n             total       used       free     shared    buffers     cached\nMem:        372916     121480     251436        776      11160      46304\n-/+ buffers/cache:      64016     308900\nSwap:      4128764          0    4128764\n\n192.168.61.12 | SUCCESS | rc=0  \n             total       used       free     shared    buffers     cached\nMem:        372916     121984     250932        776      11228      46336\n-/+ buffers/cache:      64420     308496\nSwap:      4128764          0    4128764", 
            "title": "Check memory info on app servers"
        }, 
        {
            "location": "/ad-hoc/#installing-packages", 
            "text": "Let us  install  Docker on app servers  ansible app -a  yum install -y docker-engine   This command will fail.  [Output]  192.168.61.13 | FAILED | rc=1  \nLoaded plugins: fastestmirror, prioritiesYou need to be root to perform this command.\n\n192.168.61.12 | FAILED | rc=1  \nLoaded plugins: fastestmirror, prioritiesYou need to be root to perform this command.  Run the fillowing command with sudo permissions.  ansible app -s -a  yum install -y docker-engine   This will install docker in our app servers  [Output]  192.168.61.12 | SUCCESS | rc=0  \nLoaded plugins: fastestmirror, priorities\nSetting up Install Process\nLoading mirror speeds from cached hostfile\n * base: mirrors.nhanhoa.com\n * epel: mirror.rise.ph\n * extras: mirror.fibergrid.in\n * updates: mirror.fibergrid.in\n283 packages excluded due to repository priority protections\nResolving Dependencies\n--  Running transaction check\n---  Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed\n--  Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package             Arch         Version              Repository          Size\n================================================================================\nInstalling:\n docker-engine       x86_64       1.7.1-1.el6          local_docker       4.5 M\n\nTransaction Summary\n================================================================================\nInstall       1 Package(s)\n\nTotal download size: 4.5 M\nInstalled size: 19 M\nDownloading Packages:\nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\n  Installing : docker-engine-1.7.1-1.el6.x86_64                             1/1\n  Verifying  : docker-engine-1.7.1-1.el6.x86_64                             1/1\n\nInstalled:\n  docker-engine.x86_64 0:1.7.1-1.el6\n\nComplete!\n\n192.168.61.13 | SUCCESS | rc=0  \nLoaded plugins: fastestmirror, priorities\nSetting up Install Process\nLoading mirror speeds from cached hostfile\n * base: mirror.fibergrid.in\n * epel: mirror.rise.ph\n * extras: mirror.fibergrid.in\n * updates: mirror.fibergrid.in\n283 packages excluded due to repository priority protections\nResolving Dependencies\n--  Running transaction check\n---  Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed\n--  Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package             Arch         Version              Repository          Size\n================================================================================\nInstalling:\n docker-engine       x86_64       1.7.1-1.el6          local_docker       4.5 M\n\nTransaction Summary\n================================================================================\nInstall       1 Package(s)\n\nTotal download size: 4.5 M\nInstalled size: 19 M\nDownloading Packages:\nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\n  Installing : docker-engine-1.7.1-1.el6.x86_64                             1/1\n  Verifying  : docker-engine-1.7.1-1.el6.x86_64                             1/1\n\nInstalled:\n  docker-engine.x86_64 0:1.7.1-1.el6\n\nComplete!", 
            "title": "Installing packages"
        }, 
        {
            "location": "/ad-hoc/#running-commands-one-machine-at-a-time", 
            "text": "Do you want a command to run on  one machine at a time  ?  ansible all -f 1 -a  free", 
            "title": "Running commands one machine at a time"
        }, 
        {
            "location": "/ad-hoc/#using-modules-to-manage-the-state-of-infrastructure", 
            "text": "", 
            "title": "Using modules to manage the state of infrastructure"
        }, 
        {
            "location": "/ad-hoc/#creating-users-and-groups-using-user-and-group", 
            "text": "To create a group  ansible app -s -m group -a  name=admin state=present   The output will be,  192.168.61.13 | SUCCESS =  {\n     changed : true,\n     gid : 501,\n     name :  admin ,\n     state :  present ,\n     system : false\n}\n192.168.61.12 | SUCCESS =  {\n     changed : true,\n     gid : 501,\n     name :  admin ,\n     state :  present ,\n     system : false\n}  To create a user  ansible app -s -m user -a  name=devops group=admin createhome=yes   This will create user  devops ,  192.168.61.13 | SUCCESS =  {\n     changed : true,\n     comment :  ,\n     createhome : true,\n     group : 501,\n     home :  /home/devops ,\n     name :  devops ,\n     shell :  /bin/bash ,\n     state :  present ,\n     system : false,\n     uid : 501\n}\n192.168.61.12 | SUCCESS =  {\n     changed : true,\n     comment :  ,\n     createhome : true,\n     group : 501,\n     home :  /home/devops ,\n     name :  devops ,\n     shell :  /bin/bash ,\n     state :  present ,\n     system : false,\n     uid : 501\n}", 
            "title": "Creating users and groups using user and group"
        }, 
        {
            "location": "/ad-hoc/#copy-a-file-using-copy-modules", 
            "text": "We will copy file from control node to app servers.  ansible app -m copy -a  src=/vagrant/test.txt dest=/tmp/test.txt   File will be copied over to our app server machines...  192.168.61.13 | SUCCESS =  {\n     changed : true,\n     checksum :  3160f8f941c330444aac253a9e6420cd1a65bfe2 ,\n     dest :  /tmp/test.txt ,\n     gid : 500,\n     group :  vagrant ,\n     md5sum :  9052de4cff7e8a18de586f785e711b97 ,\n     mode :  0664 ,\n     owner :  vagrant ,\n     size : 11,\n     src :  /home/vagrant/.ansible/tmp/ansible-tmp-1472991990.29-63683023616899/source ,\n     state :  file ,\n     uid : 500\n}\n192.168.61.12 | SUCCESS =  {\n     changed : true,\n     checksum :  3160f8f941c330444aac253a9e6420cd1a65bfe2 ,\n     dest :  /tmp/test.txt ,\n     gid : 500,\n     group :  vagrant ,\n     md5sum :  9052de4cff7e8a18de586f785e711b97 ,\n     mode :  0664 ,\n     owner :  vagrant ,\n     size : 11,\n     src :  /home/vagrant/.ansible/tmp/ansible-tmp-1472991990.26-218089785548663/source ,\n     state :  file ,\n     uid : 500\n}", 
            "title": "Copy a file using copy modules"
        }, 
        {
            "location": "/ad-hoc/#exercises", 
            "text": "Add another system group (not inventory group) called  lb  in inventory with respective host ip  Add a system user called  joe  on all  app servers. Make sure that the user has a home directory  Install  package  vim  using the correct  Ad-Hoc  command  Examine all the available module\nhttp://docs.ansible.com/ansible/modules_by_category.html  Find out the difference between the  command  module and  shell  module. Try running the following command with both these modules,   free | grep -i swap    Use command module to show  uptime  on the host    Install docker-engine using the yum/apt module  Using docker-image module, pull  hello-world  image on web server", 
            "title": "Exercises:"
        }, 
        {
            "location": "/modules/", 
            "text": "Modules - The batteris included", 
            "title": "Modules - The Batteries Included"
        }, 
        {
            "location": "/modules/#modules-the-batteris-included", 
            "text": "", 
            "title": "Modules - The batteris included"
        }, 
        {
            "location": "/playbooks/", 
            "text": "Learning to Write Playbooks\n\n\nIn this tutorial we are going to create a simple playbook to add system users, install and start ntp service and some basic utilities.\n\n\nAnatomy of a Playbook\n\n\nYAML - The Language to write Playbooks\n\n\nWriting and executing our first Playbook\n\n\nProblem Statement\n  \n\n\nYou have to create a playbook which will\n\n  * create a admin user with uid 5001\n  * remove  user dojo\n  * install tree  utility\n  * install ntp\n\n\non all systems which belong to  prod group in the inventory\n\n\nTo create playbook,\n\n\n\n\nChange working directory to /vagrant/code/chap5  \n\n\n\n\ncd /vagrant/code/chap5\n\n\n\n\n\n\n\n\nEdit myhosts.ini if required and comment the hosts which are absent.\n\n\n\n\n\n\nAdd the following configuration to ansible.cfg.   \n\n\n\n\n\n\nretry_files_save_path = /tmp\n\n\n\n\nThis defines the path where retry files are created in case of failed ansible run. We will learn about this in later in this chapter.\n\n\n\n\nCreate a new file with name \nplaybook.yml\n and add the following content to it\n\n\n\n\n---\n  - name: Base Configurations for ALL hosts\n    hosts: all\n    become: true\n    tasks:\n      - name: create admin user\n        user: name=admin state=present uid=5001\n\n      - name: remove dojo\n        user: name=dojo  state=absent\n\n      - name: install tree\n        yum:  name=tree  state=present\n\n      - name: install ntp\n        yum:  name=ntp   state=present\n\n\n\n\n\nValidating Syntax\n\n\nOption 1 : Using --syntax-check option with ansible-playbook\n\n\nansible-playbook playbook.yml --syntax-check\n\n\n\n\nExercise:\n   Break the syntax, run playbook with --syntax check again, and learn how it works.\n\n\nOption 2 : Using YAML Linter Online\n\n\nAnother way to validate syntax\n\n\n\n\nVisit http://www.yamllinter.com\n    \n\n\n\n\nUsing ansible-playbook utility\n\n\nWe will start using ansible-playbook utility to execute playbooks.\n\n\nTo learn how to use ansible-playbook execute the following command,\n\n\n  ansible-playbook --help\n\n\n\n\n\n[output]\n\nUsage: ansible-playbook playbook.yml\n\nOptions:\n  --ask-become-pass     ask for privilege escalation password\n  -k, --ask-pass        ask for connection password\n  --ask-su-pass         ask for su password (deprecated, use become)\n  -K, --ask-sudo-pass   ask for sudo password (deprecated, use become)\n  --ask-vault-pass      ask for vault password\n  -b, --become          run operations with become (nopasswd implied)\n  --become-method=BECOME_METHOD\n                        privilege escalation method to use (default=sudo),\n                        valid choices: [ sudo | su | pbrun | pfexec | runas |\n                        doas ]\n\n.......\n\n\n\n\nDry Run\n\n\nTo execute ansible in a check mode, which will simulate tasks on the remote nodes, without actually committing, ansible provides --check or -C option. This can be invoked as ,\n\n\nansible-playbook playbook.yml --check\n\n\n\n\n\nor\n\n\nansible-playbook playbook.yml -C\n\n\n\n\nListing Hosts, Tasks and Tags in a Playbook\n\n\nansible-playbook playbook.yml --list-hosts\n\nansible-playbook playbook.yml --list-tasks\n\nansible-playbook playbook.yml --list-tags\n\n\n\n\nExecuting Actions with Playbooks\n\n\nTo execute  the playbook, we are going to execute \nansible-playbook\n comman with playbook  YAML file as an argument. Since we have already defined the inventory and configurations, additional options are not necessary at this time.\n\n\nansible-playbook playbook.yml\n\n\n\n\n[output]\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.14]\nok: [192.168.61.11]\nok: [localhost]\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [create admin user] *******************************************************\nchanged: [192.168.61.13]\nchanged: [192.168.61.12]\nchanged: [localhost]\nchanged: [192.168.61.11]\nchanged: [192.168.61.14]\n\nTASK [remove dojo] *************************************************************\nchanged: [192.168.61.14]\nchanged: [localhost]\nchanged: [192.168.61.12]\nchanged: [192.168.61.11]\nchanged: [192.168.61.13]\n\nTASK [install tree] ************************************************************\nok: [localhost]\nok: [192.168.61.13]\nok: [192.168.61.12]\nok: [192.168.61.14]\nok: [192.168.61.11]\n\nTASK [install ntp] *************************************************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\nchanged: [192.168.61.11]\nchanged: [localhost]\nchanged: [192.168.61.14]\n\n\n\n\n\nError Handling and Debugging\n\n\nWe are now going to add a new task to the playbook that we created. This task would start ntp service on all prod hosts.\n\n\nWhen you add this task, make sure the indentation is correct.\n\n\n\n      - name: start ntp service\n        service: name=ntp state=started enabled=yes\n\n\n\n\n\n\n\nApply playbook again, check the output\n\n\n\n\nansible-playbook playbook.yml\n\n\n\n\n\n[output]\n\n\nTASK [start ntp service] *******************************************************\nfatal: [localhost]: FAILED! =\n {\nchanged\n: false, \nfailed\n: true, \nmsg\n: \nno service or tool found for: ntp\n}\nfatal: [192.168.61.11]: FAILED! =\n {\nchanged\n: false, \nfailed\n: true, \nmsg\n: \nno service or tool found for: ntp\n}\nfatal: [192.168.61.12]: FAILED! =\n {\nchanged\n: false, \nfailed\n: true, \nmsg\n: \nno service or tool found for: ntp\n}\n\nNO MORE HOSTS LEFT *************************************************************\n    to retry, use: --limit @/tmp/playbook.retry\n\nPLAY RECAP *********************************************************************\n192.168.61.11              : ok=5    changed=0    unreachable=0    failed=1\n192.168.61.12              : ok=5    changed=0    unreachable=0    failed=1\nlocalhost                  : ok=5    changed=0    unreachable=0    failed=1\n\n\n\n\nExercise : There was a intentional error introduced in the code. Identify the error from the log message above, correct it  and run the playbook again. This time you should run it  only on the failed hosts by limiting  with the retry file mentioned above (e.g. --limit @/tmp/playbook.retry )\n\n\nDebugging Technique : Step By Step Execution\n\n\nAnsible provides a way to execute tasks step by step, asking you whether to run or skip each task. This can be useful while debugging issues.\n\n\nansible-playbook playbook.yml --step\n\n\n\n\n[Output]\n\n\nroot@control:/workspace/chap5# ansible-playbook playbook.yml --step                             \n\nPLAY [Base Configurations for ALL hosts] ***************************************                \nPerform task: TASK: setup (N)o/(y)es/(c)ontinue: y                                              \n\n\nTASK [setup] *******************************************************************                \ny                                                                                               \nok: [app1]                                                                                      \nok: [db]                                                                                        \nok: [app2]                                                                                      \nok: [lb]                                                                                        \nPerform task: TASK: create admin user (N)o/(y)es/(c)ontinue:                                    \n\nTASK [create admin user] *******************************************************                \nyok: [app2]                                                                                     \nok: [app1]                                                                                      \nok: [db]                                                                                        \nok: [lb]                                                                                        \n\nPerform task: TASK: install tree (N)o/(y)es/(c)ontinue: y                                       \n\nTASK [install tree] ************************************************************                \nok: [app2]                                                                                      \nok: [lb]                                                                                        \nok: [app1]                                                                                      \nok: [db]                                                  \n\n\n\n\nAdding Additional  Play\n\n\nProblem Statement:\n\n\nYou have to a new play to existing playbook  which will\n\n\n\n\ncreate a app user with uid 5003\n\n\ninstall git\n\n\non all app servers in the inventory\n\n\n\n\nLets add a second play specific to app servers. Add the following block of code in playbook.yml file and save   \n\n\n- name: App Server Configurations\n  hosts: app\n  become: true\n  tasks:\n    - name: create app user\n      user: name=app state=present uid=5003\n\n    - name: install git\n      yum:  name=git  state=present\n\n\n\n\nRun the playbook again...  \n\n\nansible-playbook playbook.yml\n\n\n\n\n.......\n\nPLAY [App Server Configurations] ***********************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [create app user] *********************************************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nTASK [install git] *************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nPLAY RECAP *********************************************************************\n192.168.61.11              : ok=6    changed=0    unreachable=0    failed=0\n192.168.61.12              : ok=9    changed=1    unreachable=0    failed=0\n192.168.61.13              : ok=9    changed=1    unreachable=0    failed=0\n192.168.61.14              : ok=6    changed=0    unreachable=0    failed=0\nlocalhost                  : ok=6    changed=0    unreachable=0    failed=0\n\n\n\n\nLimiting the execution to a particular group\n\n\nNow run the following command to restrict the playbook execution to \napp servers\n  \n\n\nansible-playbook playbook.yml --limit app\n\n\n\n\nThis will give us the following output, plays will be executed only on app servers...  \n\n\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\n.........\n\nTASK [start ntp service] *******************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nPLAY [App Server Configurations] ***********************************************\n\n........\n\nTASK [install git] *************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=9    changed=0    unreachable=0    failed=0\n192.168.61.13              : ok=9    changed=0    unreachable=0    failed=0\n\n\n\n\n\nExercise:\n\n\nExercise1\n: Create a Playbook with the following specifications,\n\n\n\n\nIt should apply only on local host (ansible host)\n\n\nShould use become method\n\n\nShould create a \nuser\n called webadmin with shell as \"/bin/sh\"\n\n\nShould install and start \nnginx\n service\n\n\nShould \ndeploy\n a sample html app into the default web root directory of nginx using ansible's \ngit\n module.\n\n\nSource repo:  https://github.com/schoolofdevops/html-sample-app\n\n\nDeploy Path : /usr/share/nginx/html/app\n\n\n\n\n\n\nOnce deployed, validate the site by visting http://CONTROL_HOST_IP/app\n\n\n\n\nExercise 2\n: Disable Facts Gathering\n\n\n\n\nRun ansible playbook and observe the output\n\n\nAdd the following configuration parameter to ansible.cfg\n\n\n\n\ngathering = explicit\n\n\n\n\n\n\nLaunch ansible playbook run again, observe the output and compare it with the previous run.", 
            "title": "Learning to Write Infrastructure as a Code"
        }, 
        {
            "location": "/playbooks/#learning-to-write-playbooks", 
            "text": "In this tutorial we are going to create a simple playbook to add system users, install and start ntp service and some basic utilities.", 
            "title": "Learning to Write Playbooks"
        }, 
        {
            "location": "/playbooks/#anatomy-of-a-playbook", 
            "text": "", 
            "title": "Anatomy of a Playbook"
        }, 
        {
            "location": "/playbooks/#yaml-the-language-to-write-playbooks", 
            "text": "", 
            "title": "YAML - The Language to write Playbooks"
        }, 
        {
            "location": "/playbooks/#writing-and-executing-our-first-playbook", 
            "text": "Problem Statement     You have to create a playbook which will \n  * create a admin user with uid 5001\n  * remove  user dojo\n  * install tree  utility\n  * install ntp  on all systems which belong to  prod group in the inventory  To create playbook,   Change working directory to /vagrant/code/chap5     cd /vagrant/code/chap5    Edit myhosts.ini if required and comment the hosts which are absent.    Add the following configuration to ansible.cfg.       retry_files_save_path = /tmp  This defines the path where retry files are created in case of failed ansible run. We will learn about this in later in this chapter.   Create a new file with name  playbook.yml  and add the following content to it   ---\n  - name: Base Configurations for ALL hosts\n    hosts: all\n    become: true\n    tasks:\n      - name: create admin user\n        user: name=admin state=present uid=5001\n\n      - name: remove dojo\n        user: name=dojo  state=absent\n\n      - name: install tree\n        yum:  name=tree  state=present\n\n      - name: install ntp\n        yum:  name=ntp   state=present", 
            "title": "Writing and executing our first Playbook"
        }, 
        {
            "location": "/playbooks/#validating-syntax", 
            "text": "Option 1 : Using --syntax-check option with ansible-playbook  ansible-playbook playbook.yml --syntax-check  Exercise:    Break the syntax, run playbook with --syntax check again, and learn how it works.  Option 2 : Using YAML Linter Online  Another way to validate syntax   Visit http://www.yamllinter.com", 
            "title": "Validating Syntax"
        }, 
        {
            "location": "/playbooks/#using-ansible-playbook-utility", 
            "text": "We will start using ansible-playbook utility to execute playbooks.  To learn how to use ansible-playbook execute the following command,    ansible-playbook --help  [output]\n\nUsage: ansible-playbook playbook.yml\n\nOptions:\n  --ask-become-pass     ask for privilege escalation password\n  -k, --ask-pass        ask for connection password\n  --ask-su-pass         ask for su password (deprecated, use become)\n  -K, --ask-sudo-pass   ask for sudo password (deprecated, use become)\n  --ask-vault-pass      ask for vault password\n  -b, --become          run operations with become (nopasswd implied)\n  --become-method=BECOME_METHOD\n                        privilege escalation method to use (default=sudo),\n                        valid choices: [ sudo | su | pbrun | pfexec | runas |\n                        doas ]\n\n.......", 
            "title": "Using ansible-playbook utility"
        }, 
        {
            "location": "/playbooks/#dry-run", 
            "text": "To execute ansible in a check mode, which will simulate tasks on the remote nodes, without actually committing, ansible provides --check or -C option. This can be invoked as ,  ansible-playbook playbook.yml --check  or  ansible-playbook playbook.yml -C", 
            "title": "Dry Run"
        }, 
        {
            "location": "/playbooks/#listing-hosts-tasks-and-tags-in-a-playbook", 
            "text": "ansible-playbook playbook.yml --list-hosts\n\nansible-playbook playbook.yml --list-tasks\n\nansible-playbook playbook.yml --list-tags", 
            "title": "Listing Hosts, Tasks and Tags in a Playbook"
        }, 
        {
            "location": "/playbooks/#executing-actions-with-playbooks", 
            "text": "To execute  the playbook, we are going to execute  ansible-playbook  comman with playbook  YAML file as an argument. Since we have already defined the inventory and configurations, additional options are not necessary at this time.  ansible-playbook playbook.yml  [output]\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.14]\nok: [192.168.61.11]\nok: [localhost]\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [create admin user] *******************************************************\nchanged: [192.168.61.13]\nchanged: [192.168.61.12]\nchanged: [localhost]\nchanged: [192.168.61.11]\nchanged: [192.168.61.14]\n\nTASK [remove dojo] *************************************************************\nchanged: [192.168.61.14]\nchanged: [localhost]\nchanged: [192.168.61.12]\nchanged: [192.168.61.11]\nchanged: [192.168.61.13]\n\nTASK [install tree] ************************************************************\nok: [localhost]\nok: [192.168.61.13]\nok: [192.168.61.12]\nok: [192.168.61.14]\nok: [192.168.61.11]\n\nTASK [install ntp] *************************************************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\nchanged: [192.168.61.11]\nchanged: [localhost]\nchanged: [192.168.61.14]", 
            "title": "Executing Actions with Playbooks"
        }, 
        {
            "location": "/playbooks/#error-handling-and-debugging", 
            "text": "We are now going to add a new task to the playbook that we created. This task would start ntp service on all prod hosts.  When you add this task, make sure the indentation is correct.  \n      - name: start ntp service\n        service: name=ntp state=started enabled=yes   Apply playbook again, check the output   ansible-playbook playbook.yml  [output]  TASK [start ntp service] *******************************************************\nfatal: [localhost]: FAILED! =  { changed : false,  failed : true,  msg :  no service or tool found for: ntp }\nfatal: [192.168.61.11]: FAILED! =  { changed : false,  failed : true,  msg :  no service or tool found for: ntp }\nfatal: [192.168.61.12]: FAILED! =  { changed : false,  failed : true,  msg :  no service or tool found for: ntp }\n\nNO MORE HOSTS LEFT *************************************************************\n    to retry, use: --limit @/tmp/playbook.retry\n\nPLAY RECAP *********************************************************************\n192.168.61.11              : ok=5    changed=0    unreachable=0    failed=1\n192.168.61.12              : ok=5    changed=0    unreachable=0    failed=1\nlocalhost                  : ok=5    changed=0    unreachable=0    failed=1  Exercise : There was a intentional error introduced in the code. Identify the error from the log message above, correct it  and run the playbook again. This time you should run it  only on the failed hosts by limiting  with the retry file mentioned above (e.g. --limit @/tmp/playbook.retry )", 
            "title": "Error Handling and Debugging"
        }, 
        {
            "location": "/playbooks/#debugging-technique-step-by-step-execution", 
            "text": "Ansible provides a way to execute tasks step by step, asking you whether to run or skip each task. This can be useful while debugging issues.  ansible-playbook playbook.yml --step  [Output]  root@control:/workspace/chap5# ansible-playbook playbook.yml --step                             \n\nPLAY [Base Configurations for ALL hosts] ***************************************                \nPerform task: TASK: setup (N)o/(y)es/(c)ontinue: y                                              \n\n\nTASK [setup] *******************************************************************                \ny                                                                                               \nok: [app1]                                                                                      \nok: [db]                                                                                        \nok: [app2]                                                                                      \nok: [lb]                                                                                        \nPerform task: TASK: create admin user (N)o/(y)es/(c)ontinue:                                    \n\nTASK [create admin user] *******************************************************                \nyok: [app2]                                                                                     \nok: [app1]                                                                                      \nok: [db]                                                                                        \nok: [lb]                                                                                        \n\nPerform task: TASK: install tree (N)o/(y)es/(c)ontinue: y                                       \n\nTASK [install tree] ************************************************************                \nok: [app2]                                                                                      \nok: [lb]                                                                                        \nok: [app1]                                                                                      \nok: [db]", 
            "title": "Debugging Technique : Step By Step Execution"
        }, 
        {
            "location": "/playbooks/#adding-additional-play", 
            "text": "Problem Statement:  You have to a new play to existing playbook  which will   create a app user with uid 5003  install git  on all app servers in the inventory   Lets add a second play specific to app servers. Add the following block of code in playbook.yml file and save     - name: App Server Configurations\n  hosts: app\n  become: true\n  tasks:\n    - name: create app user\n      user: name=app state=present uid=5003\n\n    - name: install git\n      yum:  name=git  state=present  Run the playbook again...    ansible-playbook playbook.yml  .......\n\nPLAY [App Server Configurations] ***********************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [create app user] *********************************************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nTASK [install git] *************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nPLAY RECAP *********************************************************************\n192.168.61.11              : ok=6    changed=0    unreachable=0    failed=0\n192.168.61.12              : ok=9    changed=1    unreachable=0    failed=0\n192.168.61.13              : ok=9    changed=1    unreachable=0    failed=0\n192.168.61.14              : ok=6    changed=0    unreachable=0    failed=0\nlocalhost                  : ok=6    changed=0    unreachable=0    failed=0", 
            "title": "Adding Additional  Play"
        }, 
        {
            "location": "/playbooks/#limiting-the-execution-to-a-particular-group", 
            "text": "Now run the following command to restrict the playbook execution to  app servers     ansible-playbook playbook.yml --limit app  This will give us the following output, plays will be executed only on app servers...    \nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\n.........\n\nTASK [start ntp service] *******************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nPLAY [App Server Configurations] ***********************************************\n\n........\n\nTASK [install git] *************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=9    changed=0    unreachable=0    failed=0\n192.168.61.13              : ok=9    changed=0    unreachable=0    failed=0", 
            "title": "Limiting the execution to a particular group"
        }, 
        {
            "location": "/playbooks/#exercise", 
            "text": "", 
            "title": "Exercise:"
        }, 
        {
            "location": "/playbooks/#exercise1-create-a-playbook-with-the-following-specifications", 
            "text": "It should apply only on local host (ansible host)  Should use become method  Should create a  user  called webadmin with shell as \"/bin/sh\"  Should install and start  nginx  service  Should  deploy  a sample html app into the default web root directory of nginx using ansible's  git  module.  Source repo:  https://github.com/schoolofdevops/html-sample-app  Deploy Path : /usr/share/nginx/html/app    Once deployed, validate the site by visting http://CONTROL_HOST_IP/app", 
            "title": "Exercise1: Create a Playbook with the following specifications,"
        }, 
        {
            "location": "/playbooks/#exercise-2-disable-facts-gathering", 
            "text": "Run ansible playbook and observe the output  Add the following configuration parameter to ansible.cfg   gathering = explicit   Launch ansible playbook run again, observe the output and compare it with the previous run.", 
            "title": "Exercise 2: Disable Facts Gathering"
        }, 
        {
            "location": "/roles/", 
            "text": "Chapter 6  : Working with Roles\n\n\nIn this tutorial we are going to create simple, static role for apache which will,\n  * Install \nhttpd\n package\n  * Configure \nhttpd.conf\n, manage it as a static file\n  * Start httpd service\n  * Add a notification and a  handler so that whenever the configuration is updated, service is automatically restarted.\n\n\n6.1 Creating Role Scaffolding for Apache\n\n\n\n\nChange working  directory to \n/vagrant/code/chap5\n\n\n\n\ncd  chap6\n\n\n\n\n\n\nCreate roles directory\n\n\n\n\nmkdir roles\n\n\n\n\n\n\nGenerate role scaffolding using ansible-galaxy\n\n\n\n\nansible-galaxy init --offline --init-path=roles  apache\n\n\n\n\n\n\nValidate\n\n\n\n\ntree roles/\n\n\n\n\n[Output]\n\n\n  roles/\n    \u2514\u2500\u2500 apache\n        \u251c\u2500\u2500 defaults\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 files\n        \u251c\u2500\u2500 handlers\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 meta\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 README.md\n        \u251c\u2500\u2500 tasks\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 templates\n        \u251c\u2500\u2500 tests\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inventory\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 test.yml\n        \u2514\u2500\u2500 vars\n            \u2514\u2500\u2500 main.yml\n\n\n\n\n\n6.2 Writing Tasks to Install and Start  Apache Web Service\n\n\nWe are going to create three different tasks files, one for each phase of application lifecycle\n  * Install\n  * Configure\n  * Start Service\n\n\nTo begin with, in this part, we will install and start apache.\n\n\n\n\nTo install apache, Create \nroles/apache/tasks/install.yml\n\n\n\n\n---\n- name: Install Apache...\n  yum: name=httpd state=latest\n\n\n\n\n\n\nTo start the service, create  \nroles/apache/tasks/start.yml\n with the following content  \n\n\n\n\n---\n- name: Starting Apache...\n  service: name=httpd state=started\n\n\n\n\nTo have these tasks being called, include them into main task.\n\n\n\n\nEdit roles/apache/tasks/main.yml\n\n\n\n\n---\n# tasks file for apache\n- include: install.yml\n- include: start.yml\n\n\n\n\n\n\nCreate a playbook for app servers at /vagrant/chap5/app.yml with following contents\n\n\n\n\n  ---\n  - hosts: app\n    become: true\n    roles:\n      - apache\n\n\n\n\n\n\nApply app.yml with ansible-playbook\n\n\n\n\n  ansible-playbook app.yml\n\n\n\n\n[Output]\n\n\nPLAY [Playbook to configure App Servers] *********************************************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [apache : Install Apache...] **********************************************\nchanged: [192.168.61.13]\nchanged: [192.168.61.12]\n\nTASK [apache : Starting Apache...] *********************************************\nchanged: [192.168.61.13]\nchanged: [192.168.61.12]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=3    changed=2    unreachable=0    failed=0\n192.168.61.13              : ok=3    changed=2    unreachable=0    failed=0\n\n\n\n\n6.3 Managing Configuration files for Apache\n\n\n\n\nCopy \nindex.html\n and \nhttpd.conf\n from \nchap5/helper\n to \n/roles/apache/files/\n directory    \n\n\n\n\n    cp helper/index.html helper/httpd.conf roles/apache/files/  \n\n\n\n\n\n\nCreate a task file at \nroles/apache/tasks/config.yml\n to manage files.    \n\n\n\n\n---\n- name: Copying configuration files...\n  copy: src=httpd.conf\n        dest=/etc/httpd.conf\n        owner=root group=root mode=0644\n\n- name: Copying index.html file...\n  copy: src=index.html\n        dest=/var/www/html/index.html\n        mode=0777\n\n\n\n\n6.3.2 Adding Notifications and Handlers\n\n\n\n\nPreviously we have create a task in roles/apache/tasks/config.yml to copy over httpd.conf to the app server. Update this file to send a notification to restart  service on configuration update.  You simply have to add the line which starts with \nnotify\n\n\n\n\n  - name: Copying configuration files...\n    copy: src=httpd.conf\n          dest=/etc/httpd.conf\n          owner=root group=root mode=0644\n    notify: Restart apache service\n\n\n\n\n\n\nCreate the notification handler by updating   \nroles/apache/handlers/main.yml\n  \n\n\n\n\n---\n- name: Restart apache service\n  service: name=httpd state=restarted\n\n\n\n\n  ansible-playbook app.yml\n\n\n\n\n[Output]  \n\n\n\nPLAY [Playbook to configure App Servers] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Installing Apache...] *******************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [apache : Starting Apache...] *********************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Copying configuration files...] *********************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nTASK [apache : Copying index.html file...] *************************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nRUNNING HANDLER [apache : Restart apache service] ******************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=6    changed=3    unreachable=0    failed=0\n192.168.61.13              : ok=6    changed=3    unreachable=0    failed=0\n\n\n\n\n\nTroubleshooting Exercise\n\n\nDid the above command added the configuration files and restarted the service ? But we have already written \nconfig.yml\n. Troubleshoot why its not being run and fix it before you proceed.\n\n\n6.4 Base Role and Role Nesting\n\n\n\n\nCreate a base role with ansible-galaxy utility,  \n\n\n\n\n  ansible-galaxy init --offline --init-path=roles base\n\n\n\n\n\n\nCreate tasks for base role by editing  \n/roles/base/tasks/main.yml\n  \n\n\n\n\n---\n# tasks file for base\n# file: roles/base/tasks/main.yml\n  - name: create admin user\n    user: name=admin state=present uid=5001\n\n  - name: remove dojo\n    user: name=dojo  state=present\n\n  - name: install tree\n    yum:  name=tree  state=present\n\n  - name: install ntp\n    yum:  name=ntp   state=present\n\n  - name: start ntp service\n    service: name=ntpd state=started enabled=yes\n\n\n\n\n\n\n\nDefine base role as a dependency for  apache role,  \n\n\nUpdate meta data for Apache by editing \nroles/apache/meta/main.yml\n and adding the following\n\n\n\n\n---\ndependencies:\n - {role: base}\n\n\n\n\n6.5  Creating a Site Wide Playbook\n\n\nWe will create a site wide playbook, which will call all the plays required to configure the complete infrastructure. Currently we have a single  playbook for App Servers. However, in future we would create many.\n\n\n\n\nCreate \nsite.yml\n in /vagrant/chap5 directory and add the following content\n\n\n\n\n  ---\n  # This is a sitewide playbook\n  # filename: site.yml\n  - include: app.yml\n\n\n\n\n\n\n\nExecute sitewide playbook as\n\n\n\n\nansible-playbook site.yml\n\n\n\n\n[Output]\n\n\n\nPLAY [Playbook to configure App Servers] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : create admin user] ************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : remove dojo] ******************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : install tree] *****************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [base : install ntp] ******************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [base : start ntp service] ************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Installing Apache...] *******************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Starting Apache...] *********************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Copying configuration files...] *********************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [apache : Copying index.html file...] *************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=10   changed=0    unreachable=0    failed=0\n192.168.61.13              : ok=10   changed=0    unreachable=0    failed=0\n\n\n\n\nExercises\n\n\nExercise 1: Update Apache Configurations\n\n\n\n\nUpdate httpd.conf and change some configuration parameters. Validate the service restarts on configuration updates by applying the sitewide playbook.\n\n\n\n\nExercise 2: Create MySQL Role\n\n\n\n\nCreate a Role to install and configure MySQL server   \n\n\nCreate role scaffold for mysql  using ansible-galaxy init  \n\n\nCreate task to install \"mysql-server\" and \"MySQL-python\" packages using yum module   \n\n\nCreate a task to start mysqld service   \n\n\nManage my.cnf by creating a centralized copy in role and writing a task to copy it to all db hosts. Use helper/my.cnf as a reference. The destination for this file is /etv/my.cnf on db servers.\n\n\nWrite a handler to restart the service on configuration change. Add a notification from the copy resource created earlier.\n\n\nAdd a dependency on base role in the metadata for mysql role.  \n\n\nCreate  \ndb.yml\n playbook for configuring all database servers. Create definitions to configure \ndb\n group and to apply \nmysql\n role.", 
            "title": "Working with Roles"
        }, 
        {
            "location": "/roles/#chapter-6-working-with-roles", 
            "text": "In this tutorial we are going to create simple, static role for apache which will,\n  * Install  httpd  package\n  * Configure  httpd.conf , manage it as a static file\n  * Start httpd service\n  * Add a notification and a  handler so that whenever the configuration is updated, service is automatically restarted.", 
            "title": "Chapter 6  : Working with Roles"
        }, 
        {
            "location": "/roles/#61-creating-role-scaffolding-for-apache", 
            "text": "Change working  directory to  /vagrant/code/chap5   cd  chap6   Create roles directory   mkdir roles   Generate role scaffolding using ansible-galaxy   ansible-galaxy init --offline --init-path=roles  apache   Validate   tree roles/  [Output]    roles/\n    \u2514\u2500\u2500 apache\n        \u251c\u2500\u2500 defaults\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 files\n        \u251c\u2500\u2500 handlers\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 meta\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 README.md\n        \u251c\u2500\u2500 tasks\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n        \u251c\u2500\u2500 templates\n        \u251c\u2500\u2500 tests\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inventory\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 test.yml\n        \u2514\u2500\u2500 vars\n            \u2514\u2500\u2500 main.yml", 
            "title": "6.1 Creating Role Scaffolding for Apache"
        }, 
        {
            "location": "/roles/#62-writing-tasks-to-install-and-start-apache-web-service", 
            "text": "We are going to create three different tasks files, one for each phase of application lifecycle\n  * Install\n  * Configure\n  * Start Service  To begin with, in this part, we will install and start apache.   To install apache, Create  roles/apache/tasks/install.yml   ---\n- name: Install Apache...\n  yum: name=httpd state=latest   To start the service, create   roles/apache/tasks/start.yml  with the following content     ---\n- name: Starting Apache...\n  service: name=httpd state=started  To have these tasks being called, include them into main task.   Edit roles/apache/tasks/main.yml   ---\n# tasks file for apache\n- include: install.yml\n- include: start.yml   Create a playbook for app servers at /vagrant/chap5/app.yml with following contents     ---\n  - hosts: app\n    become: true\n    roles:\n      - apache   Apply app.yml with ansible-playbook     ansible-playbook app.yml  [Output]  PLAY [Playbook to configure App Servers] *********************************************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [apache : Install Apache...] **********************************************\nchanged: [192.168.61.13]\nchanged: [192.168.61.12]\n\nTASK [apache : Starting Apache...] *********************************************\nchanged: [192.168.61.13]\nchanged: [192.168.61.12]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=3    changed=2    unreachable=0    failed=0\n192.168.61.13              : ok=3    changed=2    unreachable=0    failed=0", 
            "title": "6.2 Writing Tasks to Install and Start  Apache Web Service"
        }, 
        {
            "location": "/roles/#63-managing-configuration-files-for-apache", 
            "text": "Copy  index.html  and  httpd.conf  from  chap5/helper  to  /roles/apache/files/  directory           cp helper/index.html helper/httpd.conf roles/apache/files/     Create a task file at  roles/apache/tasks/config.yml  to manage files.       ---\n- name: Copying configuration files...\n  copy: src=httpd.conf\n        dest=/etc/httpd.conf\n        owner=root group=root mode=0644\n\n- name: Copying index.html file...\n  copy: src=index.html\n        dest=/var/www/html/index.html\n        mode=0777", 
            "title": "6.3 Managing Configuration files for Apache"
        }, 
        {
            "location": "/roles/#632-adding-notifications-and-handlers", 
            "text": "Previously we have create a task in roles/apache/tasks/config.yml to copy over httpd.conf to the app server. Update this file to send a notification to restart  service on configuration update.  You simply have to add the line which starts with  notify     - name: Copying configuration files...\n    copy: src=httpd.conf\n          dest=/etc/httpd.conf\n          owner=root group=root mode=0644\n    notify: Restart apache service   Create the notification handler by updating    roles/apache/handlers/main.yml      ---\n- name: Restart apache service\n  service: name=httpd state=restarted    ansible-playbook app.yml  [Output]    \nPLAY [Playbook to configure App Servers] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Installing Apache...] *******************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [apache : Starting Apache...] *********************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Copying configuration files...] *********************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nTASK [apache : Copying index.html file...] *************************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nRUNNING HANDLER [apache : Restart apache service] ******************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=6    changed=3    unreachable=0    failed=0\n192.168.61.13              : ok=6    changed=3    unreachable=0    failed=0", 
            "title": "6.3.2 Adding Notifications and Handlers"
        }, 
        {
            "location": "/roles/#troubleshooting-exercise", 
            "text": "Did the above command added the configuration files and restarted the service ? But we have already written  config.yml . Troubleshoot why its not being run and fix it before you proceed.", 
            "title": "Troubleshooting Exercise"
        }, 
        {
            "location": "/roles/#64-base-role-and-role-nesting", 
            "text": "Create a base role with ansible-galaxy utility,       ansible-galaxy init --offline --init-path=roles base   Create tasks for base role by editing   /roles/base/tasks/main.yml      ---\n# tasks file for base\n# file: roles/base/tasks/main.yml\n  - name: create admin user\n    user: name=admin state=present uid=5001\n\n  - name: remove dojo\n    user: name=dojo  state=present\n\n  - name: install tree\n    yum:  name=tree  state=present\n\n  - name: install ntp\n    yum:  name=ntp   state=present\n\n  - name: start ntp service\n    service: name=ntpd state=started enabled=yes   Define base role as a dependency for  apache role,    Update meta data for Apache by editing  roles/apache/meta/main.yml  and adding the following   ---\ndependencies:\n - {role: base}", 
            "title": "6.4 Base Role and Role Nesting"
        }, 
        {
            "location": "/roles/#65-creating-a-site-wide-playbook", 
            "text": "We will create a site wide playbook, which will call all the plays required to configure the complete infrastructure. Currently we have a single  playbook for App Servers. However, in future we would create many.   Create  site.yml  in /vagrant/chap5 directory and add the following content     ---\n  # This is a sitewide playbook\n  # filename: site.yml\n  - include: app.yml   Execute sitewide playbook as   ansible-playbook site.yml  [Output]  \nPLAY [Playbook to configure App Servers] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : create admin user] ************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : remove dojo] ******************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : install tree] *****************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [base : install ntp] ******************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [base : start ntp service] ************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Installing Apache...] *******************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Starting Apache...] *********************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\nTASK [apache : Copying configuration files...] *********************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [apache : Copying index.html file...] *************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=10   changed=0    unreachable=0    failed=0\n192.168.61.13              : ok=10   changed=0    unreachable=0    failed=0", 
            "title": "6.5  Creating a Site Wide Playbook"
        }, 
        {
            "location": "/roles/#exercises", 
            "text": "", 
            "title": "Exercises"
        }, 
        {
            "location": "/roles/#exercise-1-update-apache-configurations", 
            "text": "Update httpd.conf and change some configuration parameters. Validate the service restarts on configuration updates by applying the sitewide playbook.", 
            "title": "Exercise 1: Update Apache Configurations"
        }, 
        {
            "location": "/roles/#exercise-2-create-mysql-role", 
            "text": "Create a Role to install and configure MySQL server     Create role scaffold for mysql  using ansible-galaxy init    Create task to install \"mysql-server\" and \"MySQL-python\" packages using yum module     Create a task to start mysqld service     Manage my.cnf by creating a centralized copy in role and writing a task to copy it to all db hosts. Use helper/my.cnf as a reference. The destination for this file is /etv/my.cnf on db servers.  Write a handler to restart the service on configuration change. Add a notification from the copy resource created earlier.  Add a dependency on base role in the metadata for mysql role.    Create   db.yml  playbook for configuring all database servers. Create definitions to configure  db  group and to apply  mysql  role.", 
            "title": "Exercise 2: Create MySQL Role"
        }, 
        {
            "location": "/templates_and_variables/", 
            "text": "Templates and Variables\n\n\nIn this  tutorial, we  are going to make the roles that we created earlier dynamically by adding templates and defining variables.\n\n\nVariables\n\n\nVariables are of two types\n\n\n\n\nAutomatic Variables/ Facts\n\n\nUser Defined Variables\n\n\n\n\nLets try to discover information about our systems by using facts.\n\n\nFinding Facts About Systems\n\n\n\n\nRun the following command to see to facts of db servers  \n\n\n\n\nansible db -m setup\n\n\n\n\n[Output]\n\n\n192.168.61.11 | SUCCESS =\n {\n        \nansible_facts\n: {\n            \nansible_all_ipv4_addresses\n: [\n                \n10.0.2.15\n,\n                \n192.168.61.11\n\n            ],\n            \nansible_all_ipv6_addresses\n: [\n                \nfe80::a00:27ff:fe30:3251\n,\n                \nfe80::a00:27ff:fe8e:83e0\n\n.....\n                \ntz_offset\n: \n+0100\n,\n                \nweekday\n: \nMonday\n,\n                \nweekday_number\n: \n1\n,\n                \nweeknumber\n: \n36\n,\n                \nyear\n: \n2016\n\n            }\n\n\n\n\nFiltering facts\n\n\n\n\nUse filter attribute to extract specific data\n\n\n\n\nansible db -m setup -a \nfilter=ansible_distribution\n\n\n\n\n\n[Output]\n\n\n192.168.61.11 | SUCCESS =\n {\n  \nansible_facts\n: {\n      \nansible_distribution\n: \nCentOS\n\n  },\n  \nchanged\n: false\n}  \n\n\n\n\nCreating Templates for Apache\n\n\n\n\nCreate template for apache configuration    \n\n\nThis template will change \nport number\n, \ndocument root\n and \nindex.html\n for  apache server    \n\n\nCopy \nhttpd.conf\n file from \nroles/apache/files/\n to \nroles/apache/templates\n    \n\n\n\n\ncp roles/apache/files/httpd.conf roles/apache/templates/httpd.conf.j2\n\n\n\n\n\n\nChange your working directory to templates\n\n\n\n\ncd roles/apache/templates\n\n\n\n\n\n\nChange values of following  parameters by using template variables in \nhttpd.conf.j2\n  \n\n\nListen\n\n\nDocumentRoot\n\n\nDirectoryIndex\n\n\n\n\nFollowing code depicts only the parameters changed. Rest of the configurations in \nhttpd.conf.j2\n remain as is\n\n\nListen {{ apache_port }}\nDocumentRoot \n{{ custom_root }}\n\nDirectoryIndex {{ apache_index }} index.html.var\n\n\n\n\n\n\nCreate a template for index.html as well\n\n\n\n\ncp roles/apache/files/index.html roles/apache/templates/index.html.j2\n\n\n\n\n\n\nAdd the following contents to index.html.j2\n\n\n\n\nhtml\n\n\nbody\n\n  \nh1\n  Welcome to Ansible training! \n/h1\n\n\n  \nh2\n SYSTEM INFO \n/h2\n\n  \nh4\n  ========================= \n/h4\n\n  \nh3\n Operating System : {{ ansible_distribution }} \n/h3\n\n  \nh3\n IP Address : {{ ansible_eth0['ipv4']['address'] }} \n/h3\n\n\n  \nh2\n  My Favourites \n/h2\n\n  \nh4\n  ========================= \n/h4\n\n\n  \nh3\n color     : {{ fav['color'] }} \n/h3\n\n  \nh3\n fruit     : {{ fav['fruit']   }} \n/h3\n\n  \nh3\n car       : {{ fav['car']   }} \n/h3\n\n  \nh3\n laptop    : {{ fav['laptop']   }} \n/h3\n\n  \nh4\n  ========================= \n/h4\n\n\n\n/body\n\n\n/html\n\n\n\n\n\n\nDefining Default Variables\n\n\n\n\nDefine values of the variables used in the templates above.  The default values are defined in \nroles/apache/defaults/main.yml\n . Lets edit that file and add the following,\n\n\n\n\napache_port: 80\ncustom_root: /var/www/html\napache_index: index.html\nfav:\n  color: white\n  car: fiat\n  laptop: dell\n  fruit: apple\n\n\n\n\nUpdating Tasks to use Templates\n\n\n\n\nSince we are now using template instead of static file, we need to edit \nroles/apache/tasks/config.yml\n file and use template module\n\n\nReplace \ncopy\n module with \ntemplate\n modules as follows,\n\n\n\n\n---\n- name: Creating configuration from templates...\n  template: \n\n    src=httpd.conf.j2\n    dest=/etc/httpd.conf\n    owner=root\n    group=root\n    mode=0644\n  notify: Restart apache service\n\n- name: Copying index.html file...\n  template: \n\n    src=index.html.j2\n    dest=/var/www/html/index.html\n    mode=0777\n\n\n\n\n\n\n\nDelete httpd.conf and index.html in files directory\n\n\n\n\n  rm roles/apache/files/httpd.conf\n  rm roles/apache/files/index.html\n\n\n\n\nValidating\n\n\n\n\nLet's test this template in action\n\n\n\n\nansible-playbook app.yml\n\n\n\n\n[Output]\n\n\nPLAY [Playbook to configure App Servers] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\n.....\n\nRUNNING HANDLER [apache : Restart apache service] ******************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=11   changed=3    unreachable=0    failed=0\n192.168.61.13              : ok=11   changed=3    unreachable=0    failed=0\n\n\n\n\nVariable Precedence in Action\n\n\nLets define the variables from couple of other places, to learn about the Precedence rules. We will create,\n\n group_vars\n\n playbook vars\n\n\nSince we are going to define the variables using multi level hashes, lets define the way hashes behave when defined from multiple places.\n\n\nUpdate chap7/ansible.cfg and add the following,\n\n\nhash_behaviour=merge\n\n\n\n\nLets create group_vars and create a group \nprod\n to define vars common to all prod hosts.\n\n\ncd chap7\nmkdir group_vars\ncd group_vars\ntouch prod.yml\n\n\n\n\nEdit \ngroup_vars/prod.yml\n file and add the following contents,\n\n\n---\n  fav:\n    color: blue\n    fruit: peach\n\n\n\n\nLets also add vars to playbook. Edit app.yml and add vars as below,\n\n\n---\n  - name: Playbook to configure App Servers\n    hosts: app\n    become: true\n    vars:\n      fav:\n        fruit: mango\n    roles:\n    - apache\n\n\n\n\nExecute the playbook and check the output\n\n\nansible-playbook app.yml\n\n\n\n\nIf you view the content of the html file generated, you would notice the following,\n\n\nh3\n color     : blue \n/h3\n\n\nh3\n fruit     : mango \n/h3\n\n\nh3\n car       : fiat \n/h3\n\n\nh3\n laptop    : dell \n/h3\n\n\n\n\n\n\n\n\n\n\n\nfav item\n\n\nrole defaults\n\n\ngroup_vars\n\n\nplaybook_vars\n\n\n\n\n\n\n\n\n\n\ncolor\n\n\nwhite\n\n\nblue\n\n\n\n\n\n\n\n\nfruit\n\n\nfiat\n\n\npeach\n\n\nmango\n\n\n\n\n\n\ncar\n\n\nfiat\n\n\n\n\n\n\n\n\n\n\nlaptop\n\n\napple\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvalue of color comes from group_vars/all.yml\n\n\nvalue of fruit comes from playbook vars\n\n\nvalue of car and laptop comes from role defaults\n\n\n\n\nRegistered  Variables\n\n\nLets create a playbook to run a shell command, register the result and display the value of registered variable.\n\n\nCreate \nregister.yml\n in chap6 directory\n\n\n---\n  - name: register variable example\n    hosts: local\n    tasks:\n      - name: run a shell command and register result\n        shell: \n/sbin/ifconfig eth1\n\n        register: result\n\n      - name: print registered variable\n        debug: var=result\n\n\n\n\nExecute the playbook to display information about the registered variable.\n\n\nansible-playbook  register.yml\n\n\n\n\nAdding support for Ubuntu\n\n\nApache role that we have developed supports only RedHat based systems at the moment. To add support for ubuntu (app2), we must handle platform specific differences.\n\n\ne.g.\n\n\n\n\n\n\n\n\n\n\nRedHat\n\n\nDebian\n\n\n\n\n\n\n\n\n\n\nPackage Name\n\n\nhttpd\n\n\napache2\n\n\n\n\n\n\nService Name\n\n\nhttpd\n\n\napache2\n\n\n\n\n\n\n\n\nOS specific configurations can be defined by creating role vars and by including those in tasks.\n\n\nfile: roles/apache/vars/RedHat.yml\n\n\n---\napache:\n  package:\n    name: httpd\n  service:\n    name: httpd\n    status: started\n\n\n\n\nfile: roles/apache/vars/Debian.yml\n\n\n---\napache:\n  package:\n    name: apache2\n  service:\n    name: apache2\n    status: started\n\n\n\n\nLets now selectively include those var files from tasks/main.yml .  Also selectively call configurations.\nfile: role/apache/tasks/main.yml\n\n\n---\n# tasks file for apache\n  - include_vars: \n{{ ansible_os_family }}.yml\n\n  - include: install.yml\n  - include: start.yml\n  - include: config_{{ ansible_os_family }}.yml  \n\n\n\n\nWe are now going to create two different config tasks. Since the current config is applicable to RedHat, lets rename it to config_RedHat.yml\n\n\nmv roles/apache/tasks/config.yml roles/apache/tasks/config_RedHat.yml\n\n\n\n\nWe will now create a new config for Debian\n\n\nfile: roles/apache/tasks/config_Debian.yml\n\n\n- name: Copying index.html file...\n  template: \n\n    src=index.html.j2\n    dest=/var/www/html/index.html\n    mode=0777\n\n\n\n\nUpdate tasks and handlers to install and start the correct service\n\n\ntasks/install.yml\n\n\n---\n  - name: install httpd on centos\n    package: \n\n      name={{ apache['package']['name']}}\n      state=installed\n\n\n\n\ntasks/start.yml\n\n\n---\n  - name: start httpd service\n    service: \n\n      name={{ apache['service']['name']}}\n      state={{ apache['service']['status']}}\n\n\n\n\nhandlers/main.yml\n\n\n---\n# handlers file for apache\n  - name: restart apache service\n    service: \n\n      name={{ apache['service']['name']}}\n      state=restarted\n\n\n\n\nExercises\n\n\n\n\nCreate host specific variables in host_vars/HOSTNAME for one of the app servers, and define some variables values specific to the host. See the output after applying playbook on this node.\n\n\nGenerate MySQL Configurations dynamically using templates and modules.\n\n\nCreate a template for my.cnf.  Name it as roles/mysql/templates/my.cnf.j2\n\n\nReplace parameter values with templates variables\n\n\nDefine variables in role defaults.", 
            "title": "Variables and Templates"
        }, 
        {
            "location": "/templates_and_variables/#templates-and-variables", 
            "text": "In this  tutorial, we  are going to make the roles that we created earlier dynamically by adding templates and defining variables.", 
            "title": "Templates and Variables"
        }, 
        {
            "location": "/templates_and_variables/#variables", 
            "text": "Variables are of two types   Automatic Variables/ Facts  User Defined Variables   Lets try to discover information about our systems by using facts.", 
            "title": "Variables"
        }, 
        {
            "location": "/templates_and_variables/#finding-facts-about-systems", 
            "text": "Run the following command to see to facts of db servers     ansible db -m setup  [Output]  192.168.61.11 | SUCCESS =  {\n         ansible_facts : {\n             ansible_all_ipv4_addresses : [\n                 10.0.2.15 ,\n                 192.168.61.11 \n            ],\n             ansible_all_ipv6_addresses : [\n                 fe80::a00:27ff:fe30:3251 ,\n                 fe80::a00:27ff:fe8e:83e0 \n.....\n                 tz_offset :  +0100 ,\n                 weekday :  Monday ,\n                 weekday_number :  1 ,\n                 weeknumber :  36 ,\n                 year :  2016 \n            }", 
            "title": "Finding Facts About Systems"
        }, 
        {
            "location": "/templates_and_variables/#filtering-facts", 
            "text": "Use filter attribute to extract specific data   ansible db -m setup -a  filter=ansible_distribution   [Output]  192.168.61.11 | SUCCESS =  {\n   ansible_facts : {\n       ansible_distribution :  CentOS \n  },\n   changed : false\n}", 
            "title": "Filtering facts"
        }, 
        {
            "location": "/templates_and_variables/#creating-templates-for-apache", 
            "text": "Create template for apache configuration      This template will change  port number ,  document root  and  index.html  for  apache server      Copy  httpd.conf  file from  roles/apache/files/  to  roles/apache/templates        cp roles/apache/files/httpd.conf roles/apache/templates/httpd.conf.j2   Change your working directory to templates   cd roles/apache/templates   Change values of following  parameters by using template variables in  httpd.conf.j2     Listen  DocumentRoot  DirectoryIndex   Following code depicts only the parameters changed. Rest of the configurations in  httpd.conf.j2  remain as is  Listen {{ apache_port }}\nDocumentRoot  {{ custom_root }} \nDirectoryIndex {{ apache_index }} index.html.var   Create a template for index.html as well   cp roles/apache/files/index.html roles/apache/templates/index.html.j2   Add the following contents to index.html.j2   html  body \n   h1   Welcome to Ansible training!  /h1 \n\n   h2  SYSTEM INFO  /h2 \n   h4   =========================  /h4 \n   h3  Operating System : {{ ansible_distribution }}  /h3 \n   h3  IP Address : {{ ansible_eth0['ipv4']['address'] }}  /h3 \n\n   h2   My Favourites  /h2 \n   h4   =========================  /h4 \n\n   h3  color     : {{ fav['color'] }}  /h3 \n   h3  fruit     : {{ fav['fruit']   }}  /h3 \n   h3  car       : {{ fav['car']   }}  /h3 \n   h3  laptop    : {{ fav['laptop']   }}  /h3 \n   h4   =========================  /h4  /body  /html", 
            "title": "Creating Templates for Apache"
        }, 
        {
            "location": "/templates_and_variables/#defining-default-variables", 
            "text": "Define values of the variables used in the templates above.  The default values are defined in  roles/apache/defaults/main.yml  . Lets edit that file and add the following,   apache_port: 80\ncustom_root: /var/www/html\napache_index: index.html\nfav:\n  color: white\n  car: fiat\n  laptop: dell\n  fruit: apple", 
            "title": "Defining Default Variables"
        }, 
        {
            "location": "/templates_and_variables/#updating-tasks-to-use-templates", 
            "text": "Since we are now using template instead of static file, we need to edit  roles/apache/tasks/config.yml  file and use template module  Replace  copy  module with  template  modules as follows,   ---\n- name: Creating configuration from templates...\n  template:  \n    src=httpd.conf.j2\n    dest=/etc/httpd.conf\n    owner=root\n    group=root\n    mode=0644\n  notify: Restart apache service\n\n- name: Copying index.html file...\n  template:  \n    src=index.html.j2\n    dest=/var/www/html/index.html\n    mode=0777   Delete httpd.conf and index.html in files directory     rm roles/apache/files/httpd.conf\n  rm roles/apache/files/index.html", 
            "title": "Updating Tasks to use Templates"
        }, 
        {
            "location": "/templates_and_variables/#validating", 
            "text": "Let's test this template in action   ansible-playbook app.yml  [Output]  PLAY [Playbook to configure App Servers] ***************************************\n\nTASK [setup] *******************************************************************\nok: [192.168.61.13]\nok: [192.168.61.12]\n\n.....\n\nRUNNING HANDLER [apache : Restart apache service] ******************************\nchanged: [192.168.61.12]\nchanged: [192.168.61.13]\n\nPLAY RECAP *********************************************************************\n192.168.61.12              : ok=11   changed=3    unreachable=0    failed=0\n192.168.61.13              : ok=11   changed=3    unreachable=0    failed=0", 
            "title": "Validating"
        }, 
        {
            "location": "/templates_and_variables/#variable-precedence-in-action", 
            "text": "Lets define the variables from couple of other places, to learn about the Precedence rules. We will create,  group_vars  playbook vars  Since we are going to define the variables using multi level hashes, lets define the way hashes behave when defined from multiple places.  Update chap7/ansible.cfg and add the following,  hash_behaviour=merge  Lets create group_vars and create a group  prod  to define vars common to all prod hosts.  cd chap7\nmkdir group_vars\ncd group_vars\ntouch prod.yml  Edit  group_vars/prod.yml  file and add the following contents,  ---\n  fav:\n    color: blue\n    fruit: peach  Lets also add vars to playbook. Edit app.yml and add vars as below,  ---\n  - name: Playbook to configure App Servers\n    hosts: app\n    become: true\n    vars:\n      fav:\n        fruit: mango\n    roles:\n    - apache  Execute the playbook and check the output  ansible-playbook app.yml  If you view the content of the html file generated, you would notice the following,  h3  color     : blue  /h3  h3  fruit     : mango  /h3  h3  car       : fiat  /h3  h3  laptop    : dell  /h3      fav item  role defaults  group_vars  playbook_vars      color  white  blue     fruit  fiat  peach  mango    car  fiat      laptop  apple        value of color comes from group_vars/all.yml  value of fruit comes from playbook vars  value of car and laptop comes from role defaults", 
            "title": "Variable Precedence in Action"
        }, 
        {
            "location": "/templates_and_variables/#registered-variables", 
            "text": "Lets create a playbook to run a shell command, register the result and display the value of registered variable.  Create  register.yml  in chap6 directory  ---\n  - name: register variable example\n    hosts: local\n    tasks:\n      - name: run a shell command and register result\n        shell:  /sbin/ifconfig eth1 \n        register: result\n\n      - name: print registered variable\n        debug: var=result  Execute the playbook to display information about the registered variable.  ansible-playbook  register.yml", 
            "title": "Registered  Variables"
        }, 
        {
            "location": "/templates_and_variables/#adding-support-for-ubuntu", 
            "text": "Apache role that we have developed supports only RedHat based systems at the moment. To add support for ubuntu (app2), we must handle platform specific differences.  e.g.      RedHat  Debian      Package Name  httpd  apache2    Service Name  httpd  apache2     OS specific configurations can be defined by creating role vars and by including those in tasks.  file: roles/apache/vars/RedHat.yml  ---\napache:\n  package:\n    name: httpd\n  service:\n    name: httpd\n    status: started  file: roles/apache/vars/Debian.yml  ---\napache:\n  package:\n    name: apache2\n  service:\n    name: apache2\n    status: started  Lets now selectively include those var files from tasks/main.yml .  Also selectively call configurations.\nfile: role/apache/tasks/main.yml  ---\n# tasks file for apache\n  - include_vars:  {{ ansible_os_family }}.yml \n  - include: install.yml\n  - include: start.yml\n  - include: config_{{ ansible_os_family }}.yml    We are now going to create two different config tasks. Since the current config is applicable to RedHat, lets rename it to config_RedHat.yml  mv roles/apache/tasks/config.yml roles/apache/tasks/config_RedHat.yml  We will now create a new config for Debian  file: roles/apache/tasks/config_Debian.yml  - name: Copying index.html file...\n  template:  \n    src=index.html.j2\n    dest=/var/www/html/index.html\n    mode=0777  Update tasks and handlers to install and start the correct service  tasks/install.yml  ---\n  - name: install httpd on centos\n    package:  \n      name={{ apache['package']['name']}}\n      state=installed  tasks/start.yml  ---\n  - name: start httpd service\n    service:  \n      name={{ apache['service']['name']}}\n      state={{ apache['service']['status']}}  handlers/main.yml  ---\n# handlers file for apache\n  - name: restart apache service\n    service:  \n      name={{ apache['service']['name']}}\n      state=restarted", 
            "title": "Adding support for Ubuntu"
        }, 
        {
            "location": "/templates_and_variables/#exercises", 
            "text": "Create host specific variables in host_vars/HOSTNAME for one of the app servers, and define some variables values specific to the host. See the output after applying playbook on this node.  Generate MySQL Configurations dynamically using templates and modules.  Create a template for my.cnf.  Name it as roles/mysql/templates/my.cnf.j2  Replace parameter values with templates variables  Define variables in role defaults.", 
            "title": "Exercises"
        }, 
        {
            "location": "/control_structures/", 
            "text": "Control Structures\n\n\nIn Chapter 7, we will learn about the aspects of conditionals and iterations that affects program's execution flow in Ansible\n\nControl structures are of two different type\n\n\n\n\nConditional  \n\n\nIterative  \n\n\n\n\nConditionals\n\n\nConditionals structures allow Ansible to choose an alternate path. Ansible does this by using \nwhen\n statements\n\n\nWhen\n statements\n\n\nWhen statement becomes helpful, when you will want to skip a particular step on a particular host\n\n\nSelectively calling install tasks based on platform\n\n\n\n\nEdit \nroles/apache/tasks/main.yml\n,\n\n\n\n\n---\n- include: install.yml\n  when: ansible_os_family == 'RedHat'\n- include: start.yml\n- include: config.yml\n\n\n\n\n\n\nThis will include \ninstall.yml\n only if the OS family is Redhat, otherwise it will skip the installation playbook\n\n\n\n\nConfiguring MySQL server based on boolean flag\n\n\n\n\nEdit \nroles/mysql/tasks/main.yml\n and add when statements,\n\n\n\n\n---\n- include: install.yml\n\n- include: start.yml\n  when: mysql.server\n\n- include: config.yml\n  when: mysql.server\n\n\n\n\n\n\nEdit \ndb.yml\n as follows,\n\n\n\n\n---\n- name: Playbook to configure DB Servers\n  hosts: db\n  become: true\n  roles:\n  - mysql\n  vars:\n    mysql:\n      server: true\n      config:\n        bind: \n{{ ansible_eth0.ipv4.address }}\n\n\n\n\n\nAdding conditionals in Jinja2 templates\n\n\n\n\nPut the following content in \nroles/mysql/templates/my.cnf.j2\n\n\n\n\n[mysqld]\n\n{% if mysql.config.datadir is defined %}\ndatadir={{ mysql['config']['datadir'] }}\n{% endif %}\n\n{% if mysql.config.socket is defined %}\nsocket={{ mysql['config']['socket'] }}\n{% endif %}\n\nsymbolic-links=0\nlog-error=/var/log/mysqld.log\n\n{% if mysql.config.pid is defined %}\npid-file={{ mysql['config']['pid']}}\n{% endif %}\n\n[client]\nuser=root\npassword={{ mysql_root_db_pass }}\n\n\n\n\n\n\nThese conditions will run flawlessly, because we have already defined these Variables\n\n\n\n\nRunning One Time Tasks\n\n\n\n\nTo see how this works, lets take a look at the code in \nroles/mysql/tasks/config.yml\n\n\n\n\n    [...]\n- name: reset default root password\n  shell: mysql --user=root --password=\n{{ MYSQL_DEFAULT_PASS }}\n --connect-expired-password mysql \n /root/.mysql_reset_pass.sql\n  run_once: true\n  ignore_errors: yes\n     [...]\n\n\n\n\n\n\nIn some cases there may be a need to only run a task one time and only on one host. This can be achieved by configuring \u201crun_once\u201d on a task\n\n\n\n\nConditional Execution of Roles\n\n\n\n\nThis will execute app playbook only if the node is running \nRedHat\n family\n\n\nUpdate app.yml to restrict role to be run only on RedHat platform.\n\n\n\n\n---\n  - name: Playbook to configure App Servers\n    hosts: app\n    become: true\n    vars:\n      fav:\n        fruit: mango\n    roles:\n    - { role: apache, when: ansible_os_family == 'RedHat' }\n\n\n\n\n\n\nLet's run this code\n\n\n\n\nansible-playbook site.yml\n\n\n\n\n[Output]\n\n\nTASK [setup] *******************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : create admin user] ************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : remove dojo] ******************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : install tree] *****************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : install ntp] ******************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : start ntp service] ************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Installing Apache...] *******************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Starting Apache...] *********************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Creating configuration from templates...] ***********************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Copying index.html file...] *************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\n\n\n\n\nExercise\n: Try using \nDebian\n instead of \nRedHat\n . You shall see app role being skipped altogether. Don't forget to put it back after you try this out.\n\n\nIterations\n\n\nIteration over list\n\n\n\n\nCreate a list of packages  \n\n\nLet us create the following list of packages in base role.  \n\n\nEdit \nroles/base/defaults/main.yml\n and put\n\n\n\n\n---\n# packages list\ndemolist:\n  packages:\n    - atk\n    - flac\n    - eggdbus\n    - pixman\n    - polkit\n\n\n\n\n\n\n\nAlso edit \nroles/base/tasks/main.yml\n to iterate over this list of items and install packages\n\n\n\n\n- name: install a list of packages\n  yum:\n    name: \n{{ item }}\n\n  with_items: {{ demolist.packages }}\n\n\n\n\n\n\nLet's check the output\n\n\n\n\nTASK [base : install a list of packages] ***************************************\nchanged: [192.168.61.12] =\n (item=[u'atk', u'flac', u'eggdbus', u'polkit', u'pixman'])\nchanged: [192.168.61.13] =\n (item=[u'atk', u'flac', u'eggdbus', u'polkit', u'pixman'])\n\n\n\n\nIterating over a Hash Table/Dictionary\n\n\n\n\nThis iteration can be done with using \nwith_dict\n statement, let us see how.\n\n\nEdit \ngroup_vars/all\n file from the \nparent directory\n and define a dictionary of mysql databases and users to be created\n\n\n\n\n---\n  fav:\n    color: blue\n    fruit: peach\n  mysql_bind: \n{{ ansible_eth0.ipv4.address }}\n\n  mysql:\n    databases:\n      infinity:\n        state: present\n      peace:\n        state: present\n    users:\n      dojo:\n        pass: PassWord@1234\n        host: '%'\n        priv: '*.*:ALL'\n        state: present\n      koko:\n        pass: f8Usg3ord@1we28\n        host: '%'\n        priv: '*.*:ALL'\n        state: present\n\n\n\n\n\n\n\nAppend\n the following iteration in \nroles/mysql/tasks/config.yml\n\n\n\n\n- name: create mysql databases\n  mysql_db:\n    name: \n{{ item.key }}\n\n    state: \n{{ item.value.state }}\n\n  with_dict: \n{{ mysql['databases'] }}\n\n\n- name: create mysql users\n  mysql_user:\n    name: \n{{ item.key }}\n\n    host: \n{{ item.value.host }}\n\n    password: \n{{ item.value.pass }}\n\n    priv: \n{{ item.value.priv }}\n\n    state: \n{{ item.value.state }}\n\n  with_dict: \n{{ mysql['users'] }}\n\n\n\n\n\n\n\nExecute the \ndb\n playbook to verify the output\n\n\n\n\nansible-playbook db.yml\n\n\n\n\nExercises\n\n\n\n\nDefine dictionary of properties for a new database user  in group_vars/all. Observe if it gets created automatically  output by running db.yml playbook. Validate if the user is been actually present by logging on to the mysql server and checking status.\n\n\nUpdate index.html.j2 to iterate over the dictionary of favorites and generate html content to display it instead of adding multiple lines.\n\n\nDefine a hash/dictionary  of apache virtual hosts to be created  and create a template which would iterate over that dictionary and create vhost configurations.\n\n\nLearn about what else you could loop over, as well as how to do so by reading this document http://docs.ansible.com/ansible/playbooks_loops.html#id12", 
            "title": "Control Structures"
        }, 
        {
            "location": "/control_structures/#control-structures", 
            "text": "In Chapter 7, we will learn about the aspects of conditionals and iterations that affects program's execution flow in Ansible \nControl structures are of two different type   Conditional    Iterative", 
            "title": "Control Structures"
        }, 
        {
            "location": "/control_structures/#conditionals", 
            "text": "Conditionals structures allow Ansible to choose an alternate path. Ansible does this by using  when  statements", 
            "title": "Conditionals"
        }, 
        {
            "location": "/control_structures/#when-statements", 
            "text": "When statement becomes helpful, when you will want to skip a particular step on a particular host", 
            "title": "When statements"
        }, 
        {
            "location": "/control_structures/#selectively-calling-install-tasks-based-on-platform", 
            "text": "Edit  roles/apache/tasks/main.yml ,   ---\n- include: install.yml\n  when: ansible_os_family == 'RedHat'\n- include: start.yml\n- include: config.yml   This will include  install.yml  only if the OS family is Redhat, otherwise it will skip the installation playbook", 
            "title": "Selectively calling install tasks based on platform"
        }, 
        {
            "location": "/control_structures/#configuring-mysql-server-based-on-boolean-flag", 
            "text": "Edit  roles/mysql/tasks/main.yml  and add when statements,   ---\n- include: install.yml\n\n- include: start.yml\n  when: mysql.server\n\n- include: config.yml\n  when: mysql.server   Edit  db.yml  as follows,   ---\n- name: Playbook to configure DB Servers\n  hosts: db\n  become: true\n  roles:\n  - mysql\n  vars:\n    mysql:\n      server: true\n      config:\n        bind:  {{ ansible_eth0.ipv4.address }}", 
            "title": "Configuring MySQL server based on boolean flag"
        }, 
        {
            "location": "/control_structures/#adding-conditionals-in-jinja2-templates", 
            "text": "Put the following content in  roles/mysql/templates/my.cnf.j2   [mysqld]\n\n{% if mysql.config.datadir is defined %}\ndatadir={{ mysql['config']['datadir'] }}\n{% endif %}\n\n{% if mysql.config.socket is defined %}\nsocket={{ mysql['config']['socket'] }}\n{% endif %}\n\nsymbolic-links=0\nlog-error=/var/log/mysqld.log\n\n{% if mysql.config.pid is defined %}\npid-file={{ mysql['config']['pid']}}\n{% endif %}\n\n[client]\nuser=root\npassword={{ mysql_root_db_pass }}   These conditions will run flawlessly, because we have already defined these Variables", 
            "title": "Adding conditionals in Jinja2 templates"
        }, 
        {
            "location": "/control_structures/#running-one-time-tasks", 
            "text": "To see how this works, lets take a look at the code in  roles/mysql/tasks/config.yml       [...]\n- name: reset default root password\n  shell: mysql --user=root --password= {{ MYSQL_DEFAULT_PASS }}  --connect-expired-password mysql   /root/.mysql_reset_pass.sql\n  run_once: true\n  ignore_errors: yes\n     [...]   In some cases there may be a need to only run a task one time and only on one host. This can be achieved by configuring \u201crun_once\u201d on a task", 
            "title": "Running One Time Tasks"
        }, 
        {
            "location": "/control_structures/#conditional-execution-of-roles", 
            "text": "This will execute app playbook only if the node is running  RedHat  family  Update app.yml to restrict role to be run only on RedHat platform.   ---\n  - name: Playbook to configure App Servers\n    hosts: app\n    become: true\n    vars:\n      fav:\n        fruit: mango\n    roles:\n    - { role: apache, when: ansible_os_family == 'RedHat' }   Let's run this code   ansible-playbook site.yml  [Output]  TASK [setup] *******************************************************************\nok: [192.168.61.12]\nok: [192.168.61.13]\n\nTASK [base : create admin user] ************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : remove dojo] ******************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : install tree] *****************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : install ntp] ******************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [base : start ntp service] ************************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Installing Apache...] *******************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Starting Apache...] *********************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Creating configuration from templates...] ***********************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]\n\nTASK [apache : Copying index.html file...] *************************************\nskipping: [192.168.61.12]\nskipping: [192.168.61.13]  Exercise : Try using  Debian  instead of  RedHat  . You shall see app role being skipped altogether. Don't forget to put it back after you try this out.", 
            "title": "Conditional Execution of Roles"
        }, 
        {
            "location": "/control_structures/#iterations", 
            "text": "", 
            "title": "Iterations"
        }, 
        {
            "location": "/control_structures/#iteration-over-list", 
            "text": "Create a list of packages    Let us create the following list of packages in base role.    Edit  roles/base/defaults/main.yml  and put   ---\n# packages list\ndemolist:\n  packages:\n    - atk\n    - flac\n    - eggdbus\n    - pixman\n    - polkit   Also edit  roles/base/tasks/main.yml  to iterate over this list of items and install packages   - name: install a list of packages\n  yum:\n    name:  {{ item }} \n  with_items: {{ demolist.packages }}   Let's check the output   TASK [base : install a list of packages] ***************************************\nchanged: [192.168.61.12] =  (item=[u'atk', u'flac', u'eggdbus', u'polkit', u'pixman'])\nchanged: [192.168.61.13] =  (item=[u'atk', u'flac', u'eggdbus', u'polkit', u'pixman'])", 
            "title": "Iteration over list"
        }, 
        {
            "location": "/control_structures/#iterating-over-a-hash-tabledictionary", 
            "text": "This iteration can be done with using  with_dict  statement, let us see how.  Edit  group_vars/all  file from the  parent directory  and define a dictionary of mysql databases and users to be created   ---\n  fav:\n    color: blue\n    fruit: peach\n  mysql_bind:  {{ ansible_eth0.ipv4.address }} \n  mysql:\n    databases:\n      infinity:\n        state: present\n      peace:\n        state: present\n    users:\n      dojo:\n        pass: PassWord@1234\n        host: '%'\n        priv: '*.*:ALL'\n        state: present\n      koko:\n        pass: f8Usg3ord@1we28\n        host: '%'\n        priv: '*.*:ALL'\n        state: present   Append  the following iteration in  roles/mysql/tasks/config.yml   - name: create mysql databases\n  mysql_db:\n    name:  {{ item.key }} \n    state:  {{ item.value.state }} \n  with_dict:  {{ mysql['databases'] }} \n\n- name: create mysql users\n  mysql_user:\n    name:  {{ item.key }} \n    host:  {{ item.value.host }} \n    password:  {{ item.value.pass }} \n    priv:  {{ item.value.priv }} \n    state:  {{ item.value.state }} \n  with_dict:  {{ mysql['users'] }}    Execute the  db  playbook to verify the output   ansible-playbook db.yml", 
            "title": "Iterating over a Hash Table/Dictionary"
        }, 
        {
            "location": "/control_structures/#exercises", 
            "text": "Define dictionary of properties for a new database user  in group_vars/all. Observe if it gets created automatically  output by running db.yml playbook. Validate if the user is been actually present by logging on to the mysql server and checking status.  Update index.html.j2 to iterate over the dictionary of favorites and generate html content to display it instead of adding multiple lines.  Define a hash/dictionary  of apache virtual hosts to be created  and create a template which would iterate over that dictionary and create vhost configurations.  Learn about what else you could loop over, as well as how to do so by reading this document http://docs.ansible.com/ansible/playbooks_loops.html#id12", 
            "title": "Exercises"
        }, 
        {
            "location": "/ansible-vault/", 
            "text": "Why to use Vault\n\n\n\n\nTo maintain sensitive data e.g. passwords/creds, keys etc.\n\n\nVersion control encrypted files instead of plain text\n\n\nansible-vault utility\n\n\n\n\nHowe ?\n\n\n\n\nUsed AES Cipher\n\n\nSymmetric Key\n\n\n\n\nWhat can be encrypted ?\n\n\n\n\nStructured data (yaml, json)\n\n\nVar files\n\n\ngroup_vars/hostvars\n\n\ninclude_vars or  var_files\n\n\nvar files passed at command line with \"-e @file\"\n\n\n\n\n\n\nTasks (however not very common)\n\n\nArbitory Files\n\n\n\n\nWhat can not be encrypted ?\n\n\n\n\nTemplates\n\n\n\n\nHow to encrypt/decrypt\n\n\n\n\nUsing --ask-vault-pass\n\n\nUsing --vault-password-file\n\n\n\n\nansible-vault Operations\n\n\n\n\nencrypt\n\n\ndecrypt\n\n\ncreate\n\n\nrekey\n\n\nedit\n\n\n\n\nRunning Playbooks with Vault\n\n\nansible-playbook site.yml --ask-vault-pass\nansible-playbook site.yml --vault-password-file ~/.vault_pass.txt\n\n\n\n\nAutomating Rekeying Process\n\n\n--new-vault-password-file=NEW_VAULT_PASSWORD_FILE\n\n\n\n\n\n                   new vault password file for rekey\n\n\n\nLab:\n\n\nansible-vault encrypt roles/mysql/defaults/main.yml\nansible-vault encrypt group_vars/all.yml\nansible-vault view group_vars/all.yml\nansible-playbook site.yml --ask-vault-pass", 
            "title": "Ansible Vault"
        }, 
        {
            "location": "/ansible-vault/#why-to-use-vault", 
            "text": "To maintain sensitive data e.g. passwords/creds, keys etc.  Version control encrypted files instead of plain text  ansible-vault utility", 
            "title": "Why to use Vault"
        }, 
        {
            "location": "/ansible-vault/#howe", 
            "text": "Used AES Cipher  Symmetric Key", 
            "title": "Howe ?"
        }, 
        {
            "location": "/ansible-vault/#what-can-be-encrypted", 
            "text": "Structured data (yaml, json)  Var files  group_vars/hostvars  include_vars or  var_files  var files passed at command line with \"-e @file\"    Tasks (however not very common)  Arbitory Files", 
            "title": "What can be encrypted ?"
        }, 
        {
            "location": "/ansible-vault/#what-can-not-be-encrypted", 
            "text": "Templates", 
            "title": "What can not be encrypted ?"
        }, 
        {
            "location": "/ansible-vault/#how-to-encryptdecrypt", 
            "text": "Using --ask-vault-pass  Using --vault-password-file", 
            "title": "How to encrypt/decrypt"
        }, 
        {
            "location": "/ansible-vault/#ansible-vault-operations", 
            "text": "encrypt  decrypt  create  rekey  edit", 
            "title": "ansible-vault Operations"
        }, 
        {
            "location": "/ansible-vault/#running-playbooks-with-vault", 
            "text": "ansible-playbook site.yml --ask-vault-pass\nansible-playbook site.yml --vault-password-file ~/.vault_pass.txt", 
            "title": "Running Playbooks with Vault"
        }, 
        {
            "location": "/ansible-vault/#automating-rekeying-process", 
            "text": "--new-vault-password-file=NEW_VAULT_PASSWORD_FILE                     new vault password file for rekey  Lab:  ansible-vault encrypt roles/mysql/defaults/main.yml\nansible-vault encrypt group_vars/all.yml\nansible-vault view group_vars/all.yml\nansible-playbook site.yml --ask-vault-pass", 
            "title": "Automating Rekeying Process"
        }, 
        {
            "location": "/ansible-windows/", 
            "text": "Preparing Ansible host\n\n\nsudo yum install python-pip\nsudo pip install \npywinrm\n=0.1.1\n\n\n\n\n\nPreparing Windows Host\n\n\n\n\nCreate a file and paste the below github content and save \u201cPowerShell Scripts (* .ps1)\u201d.\n\n\n\n\nhttps://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1\n\n\n\n\nDouble Click the file or open powershell and Execute it from the file path. winrm will be configured\n\n\n\n\nSetting up inventory and inventory vars\n\n\n\n\nAdd windows host to inventory by editing myhosts.ini\n\n\n\n\n    [windows]\n  windows_host_ip_or_hostname\n\n\n\n\nCreate group vars for windows group\n    - Create group_vars/windows.yml\n\n\n    ansible_ssh_user: \nadmin user\n\n    ansible_ssh_pass: \nadmin user password\n\n    ansible_ssh_port: 5986\n    ansible_connection: winrm\n    ansible_winrm_server_cert_validation: ignore\n\n\n\n\nValidate Connectivity\n\n\nansible windows -i host -m win_ping\nansible windows -i host -m setup\n\n\n\n\n\nCreate a Sample Playbook : windows.yml\n\n\n---\n- name: test raw module\n  hosts: windows\n  tasks:\n    - name: run ipconfig\n      raw: ipconfig\n      register: ipconfig\n\n    - debug: var=ipconfig\n\n    - name: test stat module on file\n      win_stat: path=\nC:/Windows/win.ini\n\n      register: stat_file\n\n    - debug: var=stat_file\n\n    - name: check stat_file result\n      assert:\n          that:\n             - \nstat_file.stat.exists\n\n             - \nnot stat_file.stat.isdir\n\n             - \nstat_file.stat.size \n 0\n\n             - \nstat_file.stat.md5\n\n\n    - name: Install IIS\n      win_feature:\n        name: \nWeb-Server\n\n        state: absent\n        restart: yes\n        include_sub_features: yes\n        include_management_tools: yes\n\n\n\n\nExecute Playbook as\n\n\nansible-playbook windows.yml\n\n\n\n\n\nReference\n\n\nhttp://darrylcauldwell.com/how-to-setup-an-ansible-test-lab-for-windows-managed-nodes-custom-windows-modules/\nhttp://docs.ansible.com/ansible/intro_windows.html", 
            "title": "Ansible on Windows"
        }, 
        {
            "location": "/ansible-windows/#preparing-ansible-host", 
            "text": "sudo yum install python-pip\nsudo pip install  pywinrm =0.1.1", 
            "title": "Preparing Ansible host"
        }, 
        {
            "location": "/ansible-windows/#preparing-windows-host", 
            "text": "Create a file and paste the below github content and save \u201cPowerShell Scripts (* .ps1)\u201d.   https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1   Double Click the file or open powershell and Execute it from the file path. winrm will be configured", 
            "title": "Preparing Windows Host"
        }, 
        {
            "location": "/ansible-windows/#setting-up-inventory-and-inventory-vars", 
            "text": "Add windows host to inventory by editing myhosts.ini       [windows]\n  windows_host_ip_or_hostname  Create group vars for windows group\n    - Create group_vars/windows.yml      ansible_ssh_user:  admin user \n    ansible_ssh_pass:  admin user password \n    ansible_ssh_port: 5986\n    ansible_connection: winrm\n    ansible_winrm_server_cert_validation: ignore  Validate Connectivity  ansible windows -i host -m win_ping\nansible windows -i host -m setup  Create a Sample Playbook : windows.yml  ---\n- name: test raw module\n  hosts: windows\n  tasks:\n    - name: run ipconfig\n      raw: ipconfig\n      register: ipconfig\n\n    - debug: var=ipconfig\n\n    - name: test stat module on file\n      win_stat: path= C:/Windows/win.ini \n      register: stat_file\n\n    - debug: var=stat_file\n\n    - name: check stat_file result\n      assert:\n          that:\n             -  stat_file.stat.exists \n             -  not stat_file.stat.isdir \n             -  stat_file.stat.size   0 \n             -  stat_file.stat.md5 \n\n    - name: Install IIS\n      win_feature:\n        name:  Web-Server \n        state: absent\n        restart: yes\n        include_sub_features: yes\n        include_management_tools: yes  Execute Playbook as  ansible-playbook windows.yml", 
            "title": "Setting up inventory and inventory vars"
        }, 
        {
            "location": "/ansible-windows/#reference", 
            "text": "http://darrylcauldwell.com/how-to-setup-an-ansible-test-lab-for-windows-managed-nodes-custom-windows-modules/\nhttp://docs.ansible.com/ansible/intro_windows.html", 
            "title": "Reference"
        }, 
        {
            "location": "/ansible-pull/", 
            "text": "ansible-pull -U  https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\n\n\n\n\nConnects to git and checks out the repo\n\n\nFinds fqdn.yml or local.yml  \n\n\nLaunches the playbook run\n\n\n\n\nansible-pull can\n  *   -C CHECKOUT, --checkout=CHECKOUT   Accept the git branch/tag/commit to Pull\n  *   -o, --only-if-changed\n\n\n  ansible-pull -U  https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nStarting Ansible Pull at 2016-11-15 14:54:53\n/usr/bin/ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nlocalhost | SUCCESS =\n {\n    \nafter\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nbefore\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nchanged\n: false,\n    \nwarnings\n: [\n        \nYour git version is too old to fully support the depth argument. Falling back to full checkouts.\n\n    ]\n}\n [WARNING]: Your git version is too old to fully support the depth argument. Falling\nback to full checkouts.\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [localhost]\n\nTASK [create admin user] *******************************************************\nok: [localhost]\n\nTASK [remove dojo] *************************************************************\nok: [localhost]\n\nTASK [install tree] ************************************************************\nok: [localhost]\n\nTASK [install ntp] *************************************************************\nok: [localhost]\n\nTASK [start ntp service] *******************************************************\nok: [localhost]\n\nPLAY RECAP *********************************************************************\nlocalhost                  : ok=6    changed=0    unreachable=0    failed=0\nansible-pull -U  https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nStarting Ansible Pull at 2016-11-15 14:54:53\n/usr/bin/ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nlocalhost | SUCCESS =\n {\n    \nafter\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nbefore\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nchanged\n: false,\n    \nwarnings\n: [\n        \nYour git version is too old to fully support the depth argument. Falling back to full checkouts.\n\n    ]\n}\n [WARNING]: Your git version is too old to fully support the depth argument. Falling\nback to full checkouts.\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [localhost]\n\nTASK [create admin user] *******************************************************\nok: [localhost]\n\nTASK [remove dojo] *************************************************************\nok: [localhost]\n\nTASK [install tree] ************************************************************\nok: [localhost]\n\nTASK [install ntp] *************************************************************\nok: [localhost]\n\nTASK [start ntp service] *******************************************************\nok: [localhost]\n\nPLAY RECAP *********************************************************************\nlocalhost                  : ok=6    changed=0    unreachable=0    failed=0", 
            "title": "Ansible Pull"
        }, 
        {
            "location": "/ansible-pull/", 
            "text": "ansible-pull -U  https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\n\n\n\n\nConnects to git and checks out the repo\n\n\nFinds fqdn.yml or local.yml  \n\n\nLaunches the playbook run\n\n\n\n\nansible-pull can\n  *   -C CHECKOUT, --checkout=CHECKOUT   Accept the git branch/tag/commit to Pull\n  *   -o, --only-if-changed\n\n\n  ansible-pull -U  https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nStarting Ansible Pull at 2016-11-15 14:54:53\n/usr/bin/ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nlocalhost | SUCCESS =\n {\n    \nafter\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nbefore\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nchanged\n: false,\n    \nwarnings\n: [\n        \nYour git version is too old to fully support the depth argument. Falling back to full checkouts.\n\n    ]\n}\n [WARNING]: Your git version is too old to fully support the depth argument. Falling\nback to full checkouts.\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [localhost]\n\nTASK [create admin user] *******************************************************\nok: [localhost]\n\nTASK [remove dojo] *************************************************************\nok: [localhost]\n\nTASK [install tree] ************************************************************\nok: [localhost]\n\nTASK [install ntp] *************************************************************\nok: [localhost]\n\nTASK [start ntp service] *******************************************************\nok: [localhost]\n\nPLAY RECAP *********************************************************************\nlocalhost                  : ok=6    changed=0    unreachable=0    failed=0\nansible-pull -U  https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nStarting Ansible Pull at 2016-11-15 14:54:53\n/usr/bin/ansible-pull -U https://github.com/schoolofdevops/ansible-repo -i myhosts.ini\nlocalhost | SUCCESS =\n {\n    \nafter\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nbefore\n: \nf93d954e4bdc3aebbe4fba690ceccf1f8285e508\n,\n    \nchanged\n: false,\n    \nwarnings\n: [\n        \nYour git version is too old to fully support the depth argument. Falling back to full checkouts.\n\n    ]\n}\n [WARNING]: Your git version is too old to fully support the depth argument. Falling\nback to full checkouts.\n\nPLAY [Base Configurations for ALL hosts] ***************************************\n\nTASK [setup] *******************************************************************\nok: [localhost]\n\nTASK [create admin user] *******************************************************\nok: [localhost]\n\nTASK [remove dojo] *************************************************************\nok: [localhost]\n\nTASK [install tree] ************************************************************\nok: [localhost]\n\nTASK [install ntp] *************************************************************\nok: [localhost]\n\nTASK [start ntp service] *******************************************************\nok: [localhost]\n\nPLAY RECAP *********************************************************************\nlocalhost                  : ok=6    changed=0    unreachable=0    failed=0", 
            "title": "Ansible Tower"
        }, 
        {
            "location": "/registered_variables/", 
            "text": "(src: http://docs.ansible.com/ansible/test_strategies.html)\n\n\ntasks:\n\n\n\n\n\n\naction: uri url=http://www.example.com return_content=yes\n    register: webpage\n\n\n\n\n\n\nfail: msg='service is not happy'\n    when: \"'AWESOME' not in webpage.content\"\n\n\n\n\n\n\ntasks:\n\n\n\n\n\n\nshell: /usr/bin/some-command --parameter value\n     register: cmd_result\n\n\n\n\n\n\nassert:\n       that:\n         - \"'not ready' not in cmd_result.stderr\"\n         - \"'gizmo enabled' in cmd_result.stdout\"\n\n\n\n\n\n\ntasks:\n\n\n\n\n\n\nstat: path=/path/to/something\n     register: p\n\n\n\n\n\n\nassert:\n       that:\n         - p.stat.exists and p.stat.isdir", 
            "title": "Registered Variable"
        }, 
        {
            "location": "/troubleshooting/", 
            "text": "Troubleshooting Techniques\n  * Using verbose mode\n  * Using --start-at-task\n  * Using --step\n  * Using debugger\n\n\nVerbose Mode\n -vvvv\n\n\nDebugger\n\n\nhttp://docs.ansible.com/ansible/playbooks_debugger.html\n\n\nDefining Failure\nfailed_when: \"'FAILED' in command_result.stderr\"\nhttp://docs.ansible.com/ansible/playbooks_error_handling.html\n\n\nstart-at-task\nansible-playbook playbook.yml --start-at-task=\"install packages\"\n\n\nStep\nPlaybooks can also be executed interactively with --step:\n\n\nansible-playbook playbook.yml --step\nThis will cause ansible to stop on each t\n\n\nhttp://docs.ansible.com/ansible/playbooks_startnstep.html", 
            "title": "Troubleshooting Techniques"
        }
    ]
}